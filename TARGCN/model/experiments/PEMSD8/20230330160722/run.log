2023-03-30 16:07: Experiment log path in: C:\旧电脑文件\毕业相关\第二个模型\TATCN\TARGCN\model\experiments\PEMSD8\20230330160722
2023-03-30 16:07: Train Epoch 1: 0/167 Loss: 228.840469
2023-03-30 16:07: Train Epoch 1: 20/167 Loss: 102.311157
2023-03-30 16:07: Train Epoch 1: 40/167 Loss: 75.618958
2023-03-30 16:07: Train Epoch 1: 60/167 Loss: 57.087673
2023-03-30 16:07: Train Epoch 1: 80/167 Loss: 58.970039
2023-03-30 16:07: Train Epoch 1: 100/167 Loss: 46.229736
2023-03-30 16:07: Train Epoch 1: 120/167 Loss: 40.110882
2023-03-30 16:07: Train Epoch 1: 140/167 Loss: 37.451263
2023-03-30 16:08: Train Epoch 1: 160/167 Loss: 42.031498
2023-03-30 16:08: **********Train Epoch 1: averaged Loss: 70.466297, tf_ratio: 1.000000
2023-03-30 16:08: **********Val Epoch 1: average Loss: 40.538666
2023-03-30 16:08: ******Current best model saved:model_para/PEMSD8/epoch_1.pth!
2023-03-30 16:08: Train Epoch 2: 0/167 Loss: 37.501942
2023-03-30 16:08: Train Epoch 2: 20/167 Loss: 35.304699
2023-03-30 16:08: Train Epoch 2: 40/167 Loss: 34.217819
2023-03-30 16:08: Train Epoch 2: 60/167 Loss: 31.945808
2023-03-30 16:08: Train Epoch 2: 80/167 Loss: 32.563705
2023-03-30 16:08: Train Epoch 2: 100/167 Loss: 30.958382
2023-03-30 16:08: Train Epoch 2: 120/167 Loss: 33.075363
2023-03-30 16:08: Train Epoch 2: 140/167 Loss: 31.948332
2023-03-30 16:08: Train Epoch 2: 160/167 Loss: 34.983757
2023-03-30 16:08: **********Train Epoch 2: averaged Loss: 34.424850, tf_ratio: 1.000000
2023-03-30 16:08: **********Val Epoch 2: average Loss: 33.687227
2023-03-30 16:08: ******Current best model saved:model_para/PEMSD8/epoch_2.pth!
2023-03-30 16:08: Train Epoch 3: 0/167 Loss: 29.392818
2023-03-30 16:08: Train Epoch 3: 20/167 Loss: 30.888346
2023-03-30 16:08: Train Epoch 3: 40/167 Loss: 29.217989
2023-03-30 16:09: Train Epoch 3: 60/167 Loss: 33.916889
2023-03-30 16:09: Train Epoch 3: 80/167 Loss: 29.090899
2023-03-30 16:09: Train Epoch 3: 100/167 Loss: 30.697462
2023-03-30 16:09: Train Epoch 3: 120/167 Loss: 33.015244
2023-03-30 16:09: Train Epoch 3: 140/167 Loss: 28.807381
2023-03-30 16:09: Train Epoch 3: 160/167 Loss: 34.478058
2023-03-30 16:09: **********Train Epoch 3: averaged Loss: 31.302862, tf_ratio: 1.000000
2023-03-30 16:09: **********Val Epoch 3: average Loss: 37.226448
2023-03-30 16:09: Train Epoch 4: 0/167 Loss: 37.105484
2023-03-30 16:09: Train Epoch 4: 20/167 Loss: 29.518356
2023-03-30 16:09: Train Epoch 4: 40/167 Loss: 31.363762
2023-03-30 16:09: Train Epoch 4: 60/167 Loss: 29.265125
2023-03-30 16:09: Train Epoch 4: 80/167 Loss: 34.884087
2023-03-30 16:09: Train Epoch 4: 100/167 Loss: 31.570417
2023-03-30 16:10: Train Epoch 4: 120/167 Loss: 28.057083
2023-03-30 16:10: Train Epoch 4: 140/167 Loss: 26.858145
2023-03-30 16:10: Train Epoch 4: 160/167 Loss: 27.081293
2023-03-30 16:10: **********Train Epoch 4: averaged Loss: 30.811698, tf_ratio: 1.000000
2023-03-30 16:10: **********Val Epoch 4: average Loss: 28.519637
2023-03-30 16:10: ******Current best model saved:model_para/PEMSD8/epoch_4.pth!
2023-03-30 16:10: Train Epoch 5: 0/167 Loss: 26.561666
2023-03-30 16:10: Train Epoch 5: 20/167 Loss: 29.712454
2023-03-30 16:10: Train Epoch 5: 40/167 Loss: 26.920851
2023-03-30 16:10: Train Epoch 5: 60/167 Loss: 26.821800
2023-03-30 16:10: Train Epoch 5: 80/167 Loss: 27.557148
2023-03-30 16:10: Train Epoch 5: 100/167 Loss: 26.196697
2023-03-30 16:10: Train Epoch 5: 120/167 Loss: 47.711014
2023-03-30 16:10: Train Epoch 5: 140/167 Loss: 36.915291
2023-03-30 16:10: Train Epoch 5: 160/167 Loss: 31.743431
2023-03-30 16:10: **********Train Epoch 5: averaged Loss: 32.642870, tf_ratio: 1.000000
2023-03-30 16:10: **********Val Epoch 5: average Loss: 31.151445
2023-03-30 16:10: Train Epoch 6: 0/167 Loss: 29.654486
2023-03-30 16:11: Train Epoch 6: 20/167 Loss: 30.531237
2023-03-30 16:11: Train Epoch 6: 40/167 Loss: 29.579269
2023-03-30 16:11: Train Epoch 6: 60/167 Loss: 28.869379
2023-03-30 16:11: Train Epoch 6: 80/167 Loss: 27.329710
2023-03-30 16:11: Train Epoch 6: 100/167 Loss: 29.008680
2023-03-30 16:11: Train Epoch 6: 120/167 Loss: 28.042635
2023-03-30 16:11: Train Epoch 6: 140/167 Loss: 27.954830
2023-03-30 16:11: Train Epoch 6: 160/167 Loss: 39.034924
2023-03-30 16:11: **********Train Epoch 6: averaged Loss: 29.319834, tf_ratio: 1.000000
2023-03-30 16:11: **********Val Epoch 6: average Loss: 39.930455
2023-03-30 16:11: Train Epoch 7: 0/167 Loss: 27.700327
2023-03-30 16:11: Train Epoch 7: 20/167 Loss: 25.840544
2023-03-30 16:11: Train Epoch 7: 40/167 Loss: 26.624914
2023-03-30 16:11: Train Epoch 7: 60/167 Loss: 28.094835
2023-03-30 16:12: Train Epoch 7: 80/167 Loss: 29.238674
2023-03-30 16:12: Train Epoch 7: 100/167 Loss: 27.377453
2023-03-30 16:12: Train Epoch 7: 120/167 Loss: 27.381741
2023-03-30 16:12: Train Epoch 7: 140/167 Loss: 26.905558
2023-03-30 16:12: Train Epoch 7: 160/167 Loss: 32.813374
2023-03-30 16:12: **********Train Epoch 7: averaged Loss: 27.924873, tf_ratio: 1.000000
2023-03-30 16:12: **********Val Epoch 7: average Loss: 48.504450
2023-03-30 16:12: Train Epoch 8: 0/167 Loss: 32.980087
2023-03-30 16:12: Train Epoch 8: 20/167 Loss: 26.396954
2023-03-30 16:12: Train Epoch 8: 40/167 Loss: 25.625591
2023-03-30 16:12: Train Epoch 8: 60/167 Loss: 25.838909
2023-03-30 16:12: Train Epoch 8: 80/167 Loss: 25.181492
2023-03-30 16:12: Train Epoch 8: 100/167 Loss: 28.323088
2023-03-30 16:12: Train Epoch 8: 120/167 Loss: 26.793852
2023-03-30 16:12: Train Epoch 8: 140/167 Loss: 28.423412
2023-03-30 16:13: Train Epoch 8: 160/167 Loss: 24.069426
2023-03-30 16:13: **********Train Epoch 8: averaged Loss: 26.568885, tf_ratio: 1.000000
2023-03-30 16:13: **********Val Epoch 8: average Loss: 29.256843
2023-03-30 16:13: Train Epoch 9: 0/167 Loss: 25.963583
2023-03-30 16:13: Train Epoch 9: 20/167 Loss: 25.517834
2023-03-30 16:13: Train Epoch 9: 40/167 Loss: 24.910351
2023-03-30 16:13: Train Epoch 9: 60/167 Loss: 24.169559
2023-03-30 16:13: Train Epoch 9: 80/167 Loss: 24.878563
2023-03-30 16:13: Train Epoch 9: 100/167 Loss: 25.389038
2023-03-30 16:13: Train Epoch 9: 120/167 Loss: 25.686754
2023-03-30 16:13: Train Epoch 9: 140/167 Loss: 24.249125
2023-03-30 16:13: Train Epoch 9: 160/167 Loss: 22.805058
2023-03-30 16:13: **********Train Epoch 9: averaged Loss: 25.887520, tf_ratio: 1.000000
2023-03-30 16:13: **********Val Epoch 9: average Loss: 107.539988
2023-03-30 16:13: Train Epoch 10: 0/167 Loss: 38.962318
2023-03-30 16:13: Train Epoch 10: 20/167 Loss: 46.635052
2023-03-30 16:13: Train Epoch 10: 40/167 Loss: 32.176205
2023-03-30 16:14: Train Epoch 10: 60/167 Loss: 76.974388
2023-03-30 16:14: Train Epoch 10: 80/167 Loss: 128.250717
2023-03-30 16:14: Train Epoch 10: 100/167 Loss: 62.141262
2023-03-30 16:14: Train Epoch 10: 120/167 Loss: 43.313644
2023-03-30 16:14: Train Epoch 10: 140/167 Loss: 48.195045
2023-03-30 16:14: Train Epoch 10: 160/167 Loss: 47.924728
2023-03-30 16:14: **********Train Epoch 10: averaged Loss: 56.967122, tf_ratio: 1.000000
2023-03-30 16:14: **********Val Epoch 10: average Loss: 45.633940
2023-03-30 16:14: Train Epoch 11: 0/167 Loss: 42.706680
2023-03-30 16:14: Train Epoch 11: 20/167 Loss: 45.075012
2023-03-30 16:14: Train Epoch 11: 40/167 Loss: 36.101898
2023-03-30 16:14: Train Epoch 11: 60/167 Loss: 35.502293
2023-03-30 16:14: Train Epoch 11: 80/167 Loss: 34.017124
2023-03-30 16:14: Train Epoch 11: 100/167 Loss: 37.230732
2023-03-30 16:15: Train Epoch 11: 120/167 Loss: 32.236744
2023-03-30 16:15: Train Epoch 11: 140/167 Loss: 31.991903
2023-03-30 16:15: Train Epoch 11: 160/167 Loss: 33.383701
2023-03-30 16:15: **********Train Epoch 11: averaged Loss: 37.833745, tf_ratio: 1.000000
2023-03-30 16:15: **********Val Epoch 11: average Loss: 34.565453
2023-03-30 16:15: Train Epoch 12: 0/167 Loss: 31.290174
