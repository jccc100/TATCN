2023-05-18 15:30: Experiment log path in: C:\旧电脑文件\毕业相关\第二个模型\TATCN\TARGCN\model\experiments\PEMSD8\20230518153056
2023-05-18 15:30: Train Epoch 1: 0/167 Loss: 241.426880
2023-05-18 15:31: Train Epoch 1: 20/167 Loss: 54.396412
2023-05-18 15:31: Train Epoch 1: 40/167 Loss: 34.689556
2023-05-18 15:31: Train Epoch 1: 60/167 Loss: 29.439339
2023-05-18 15:31: Train Epoch 1: 80/167 Loss: 27.656454
2023-05-18 15:31: Train Epoch 1: 100/167 Loss: 27.604673
2023-05-18 15:31: Train Epoch 1: 120/167 Loss: 29.610317
2023-05-18 15:31: Train Epoch 1: 140/167 Loss: 25.176081
2023-05-18 15:31: Train Epoch 1: 160/167 Loss: 26.985289
2023-05-18 15:31: **********Train Epoch 1: averaged Loss: 40.058981, tf_ratio: 1.000000
2023-05-18 15:31: **********Val Epoch 1: average Loss: 27.757937
2023-05-18 15:31: ******Current best model saved:model_para/PEMSD8/epoch_1.pth!
2023-05-18 15:31: Train Epoch 2: 0/167 Loss: 25.611729
2023-05-18 15:31: Train Epoch 2: 20/167 Loss: 27.280319
2023-05-18 15:31: Train Epoch 2: 40/167 Loss: 27.218916
2023-05-18 15:31: Train Epoch 2: 60/167 Loss: 24.787107
2023-05-18 15:31: Train Epoch 2: 80/167 Loss: 25.063969
2023-05-18 15:31: Train Epoch 2: 100/167 Loss: 24.398527
2023-05-18 15:31: Train Epoch 2: 120/167 Loss: 24.927505
2023-05-18 15:31: Train Epoch 2: 140/167 Loss: 22.304827
2023-05-18 15:31: Train Epoch 2: 160/167 Loss: 24.223940
2023-05-18 15:31: **********Train Epoch 2: averaged Loss: 25.249565, tf_ratio: 1.000000
2023-05-18 15:31: **********Val Epoch 2: average Loss: 24.480825
2023-05-18 15:31: ******Current best model saved:model_para/PEMSD8/epoch_2.pth!
2023-05-18 15:31: Train Epoch 3: 0/167 Loss: 23.835121
2023-05-18 15:31: Train Epoch 3: 20/167 Loss: 23.412050
2023-05-18 15:31: Train Epoch 3: 40/167 Loss: 23.721210
2023-05-18 15:31: Train Epoch 3: 60/167 Loss: 23.340216
2023-05-18 15:31: Train Epoch 3: 80/167 Loss: 22.422953
2023-05-18 15:31: Train Epoch 3: 100/167 Loss: 23.136641
2023-05-18 15:31: Train Epoch 3: 120/167 Loss: 24.778540
2023-05-18 15:31: Train Epoch 3: 140/167 Loss: 22.281027
2023-05-18 15:31: Train Epoch 3: 160/167 Loss: 23.563999
2023-05-18 15:31: **********Train Epoch 3: averaged Loss: 22.960142, tf_ratio: 1.000000
2023-05-18 15:31: **********Val Epoch 3: average Loss: 23.650396
2023-05-18 15:31: ******Current best model saved:model_para/PEMSD8/epoch_3.pth!
2023-05-18 15:31: Train Epoch 4: 0/167 Loss: 23.458319
2023-05-18 15:31: Train Epoch 4: 20/167 Loss: 21.224144
2023-05-18 15:31: Train Epoch 4: 40/167 Loss: 20.587811
2023-05-18 15:31: Train Epoch 4: 60/167 Loss: 23.177851
2023-05-18 15:31: Train Epoch 4: 80/167 Loss: 21.749826
2023-05-18 15:32: Train Epoch 4: 100/167 Loss: 22.144611
2023-05-18 15:32: Train Epoch 4: 120/167 Loss: 21.830473
2023-05-18 15:32: Train Epoch 4: 140/167 Loss: 24.736046
2023-05-18 15:32: Train Epoch 4: 160/167 Loss: 21.933710
2023-05-18 15:32: **********Train Epoch 4: averaged Loss: 22.214403, tf_ratio: 1.000000
2023-05-18 15:32: **********Val Epoch 4: average Loss: 22.491654
2023-05-18 15:32: ******Current best model saved:model_para/PEMSD8/epoch_4.pth!
2023-05-18 15:32: Train Epoch 5: 0/167 Loss: 22.057823
2023-05-18 15:32: Train Epoch 5: 20/167 Loss: 22.759640
2023-05-18 15:32: Train Epoch 5: 40/167 Loss: 20.949030
2023-05-18 15:32: Train Epoch 5: 60/167 Loss: 20.740734
2023-05-18 15:32: Train Epoch 5: 80/167 Loss: 23.072115
2023-05-18 15:32: Train Epoch 5: 100/167 Loss: 19.632320
2023-05-18 15:32: Train Epoch 5: 120/167 Loss: 22.399458
2023-05-18 15:32: Train Epoch 5: 140/167 Loss: 22.389933
2023-05-18 15:32: Train Epoch 5: 160/167 Loss: 21.720860
2023-05-18 15:32: **********Train Epoch 5: averaged Loss: 21.454654, tf_ratio: 1.000000
2023-05-18 15:32: **********Val Epoch 5: average Loss: 21.502370
2023-05-18 15:32: ******Current best model saved:model_para/PEMSD8/epoch_5.pth!
2023-05-18 15:32: Train Epoch 6: 0/167 Loss: 22.737608
2023-05-18 15:32: Train Epoch 6: 20/167 Loss: 21.336136
2023-05-18 15:32: Train Epoch 6: 40/167 Loss: 21.172882
2023-05-18 15:32: Train Epoch 6: 60/167 Loss: 21.254889
2023-05-18 15:32: Train Epoch 6: 80/167 Loss: 20.786180
2023-05-18 15:32: Train Epoch 6: 100/167 Loss: 20.937378
2023-05-18 15:32: Train Epoch 6: 120/167 Loss: 21.153183
2023-05-18 15:32: Train Epoch 6: 140/167 Loss: 22.577284
2023-05-18 15:32: Train Epoch 6: 160/167 Loss: 21.411776
2023-05-18 15:32: **********Train Epoch 6: averaged Loss: 21.115508, tf_ratio: 1.000000
2023-05-18 15:32: **********Val Epoch 6: average Loss: 21.558682
2023-05-18 15:32: Train Epoch 7: 0/167 Loss: 22.341013
2023-05-18 15:32: Train Epoch 7: 20/167 Loss: 21.797291
2023-05-18 15:32: Train Epoch 7: 40/167 Loss: 21.837433
2023-05-18 15:32: Train Epoch 7: 60/167 Loss: 20.468679
2023-05-18 15:32: Train Epoch 7: 80/167 Loss: 22.055428
2023-05-18 15:32: Train Epoch 7: 100/167 Loss: 20.332773
2023-05-18 15:32: Train Epoch 7: 120/167 Loss: 22.736361
2023-05-18 15:32: Train Epoch 7: 140/167 Loss: 19.625774
2023-05-18 15:32: Train Epoch 7: 160/167 Loss: 22.158424
2023-05-18 15:33: **********Train Epoch 7: averaged Loss: 21.015178, tf_ratio: 1.000000
2023-05-18 15:33: **********Val Epoch 7: average Loss: 21.155546
2023-05-18 15:33: ******Current best model saved:model_para/PEMSD8/epoch_7.pth!
2023-05-18 15:33: Train Epoch 8: 0/167 Loss: 20.238125
2023-05-18 15:33: Train Epoch 8: 20/167 Loss: 20.002754
2023-05-18 15:33: Train Epoch 8: 40/167 Loss: 21.374638
2023-05-18 15:33: Train Epoch 8: 60/167 Loss: 21.450342
2023-05-18 15:33: Train Epoch 8: 80/167 Loss: 21.144623
2023-05-18 15:33: Train Epoch 8: 100/167 Loss: 20.793676
2023-05-18 15:33: Train Epoch 8: 120/167 Loss: 20.984951
2023-05-18 15:33: Train Epoch 8: 140/167 Loss: 19.952061
2023-05-18 15:33: Train Epoch 8: 160/167 Loss: 21.388044
2023-05-18 15:33: **********Train Epoch 8: averaged Loss: 20.903737, tf_ratio: 1.000000
2023-05-18 15:33: **********Val Epoch 8: average Loss: 20.828026
2023-05-18 15:33: ******Current best model saved:model_para/PEMSD8/epoch_8.pth!
2023-05-18 15:33: Train Epoch 9: 0/167 Loss: 18.565641
2023-05-18 15:33: Train Epoch 9: 20/167 Loss: 20.837885
2023-05-18 15:33: Train Epoch 9: 40/167 Loss: 20.055681
2023-05-18 15:33: Train Epoch 9: 60/167 Loss: 19.011356
2023-05-18 15:33: Train Epoch 9: 80/167 Loss: 20.186682
2023-05-18 15:33: Train Epoch 9: 100/167 Loss: 21.542887
2023-05-18 15:33: Train Epoch 9: 120/167 Loss: 20.527475
2023-05-18 15:33: Train Epoch 9: 140/167 Loss: 21.196733
2023-05-18 15:33: Train Epoch 9: 160/167 Loss: 20.714701
2023-05-18 15:33: **********Train Epoch 9: averaged Loss: 20.568961, tf_ratio: 1.000000
2023-05-18 15:33: **********Val Epoch 9: average Loss: 20.823702
2023-05-18 15:33: ******Current best model saved:model_para/PEMSD8/epoch_9.pth!
2023-05-18 15:33: Train Epoch 10: 0/167 Loss: 20.214945
2023-05-18 15:33: Train Epoch 10: 20/167 Loss: 21.944012
2023-05-18 15:33: Train Epoch 10: 40/167 Loss: 20.747261
2023-05-18 15:33: Train Epoch 10: 60/167 Loss: 20.711500
2023-05-18 15:33: Train Epoch 10: 80/167 Loss: 20.593697
2023-05-18 15:33: Train Epoch 10: 100/167 Loss: 21.948534
2023-05-18 15:33: Train Epoch 10: 120/167 Loss: 21.009510
2023-05-18 15:33: Train Epoch 10: 140/167 Loss: 21.642429
2023-05-18 15:33: Train Epoch 10: 160/167 Loss: 21.216230
2023-05-18 15:33: **********Train Epoch 10: averaged Loss: 20.660903, tf_ratio: 1.000000
2023-05-18 15:33: **********Val Epoch 10: average Loss: 20.571590
2023-05-18 15:33: ******Current best model saved:model_para/PEMSD8/epoch_10.pth!
2023-05-18 15:33: Train Epoch 11: 0/167 Loss: 20.000738
2023-05-18 15:33: Train Epoch 11: 20/167 Loss: 19.210093
2023-05-18 15:33: Train Epoch 11: 40/167 Loss: 19.650410
2023-05-18 15:34: Train Epoch 11: 60/167 Loss: 19.934736
2023-05-18 15:34: Train Epoch 11: 80/167 Loss: 20.455202
2023-05-18 15:34: Train Epoch 11: 100/167 Loss: 20.586006
2023-05-18 15:34: Train Epoch 11: 120/167 Loss: 19.955339
2023-05-18 15:34: Train Epoch 11: 140/167 Loss: 20.022863
2023-05-18 15:34: Train Epoch 11: 160/167 Loss: 19.615610
2023-05-18 15:34: **********Train Epoch 11: averaged Loss: 20.462919, tf_ratio: 1.000000
2023-05-18 15:34: **********Val Epoch 11: average Loss: 20.629118
2023-05-18 15:34: Train Epoch 12: 0/167 Loss: 20.005663
2023-05-18 15:34: Train Epoch 12: 20/167 Loss: 22.577854
2023-05-18 15:34: Train Epoch 12: 40/167 Loss: 20.193495
2023-05-18 15:34: Train Epoch 12: 60/167 Loss: 20.026962
2023-05-18 15:34: Train Epoch 12: 80/167 Loss: 21.154018
2023-05-18 15:34: Train Epoch 12: 100/167 Loss: 20.588408
2023-05-18 15:34: Train Epoch 12: 120/167 Loss: 20.617495
2023-05-18 15:34: Train Epoch 12: 140/167 Loss: 20.557711
2023-05-18 15:34: Train Epoch 12: 160/167 Loss: 20.560865
2023-05-18 15:34: **********Train Epoch 12: averaged Loss: 20.262695, tf_ratio: 1.000000
2023-05-18 15:34: **********Val Epoch 12: average Loss: 20.884350
2023-05-18 15:34: Train Epoch 13: 0/167 Loss: 22.640854
2023-05-18 15:34: Train Epoch 13: 20/167 Loss: 19.204401
2023-05-18 15:34: Train Epoch 13: 40/167 Loss: 21.010790
2023-05-18 15:34: Train Epoch 13: 60/167 Loss: 20.229771
2023-05-18 15:34: Train Epoch 13: 80/167 Loss: 20.448891
2023-05-18 15:34: Train Epoch 13: 100/167 Loss: 20.785589
2023-05-18 15:34: Train Epoch 13: 120/167 Loss: 20.010612
2023-05-18 15:34: Train Epoch 13: 140/167 Loss: 18.873281
2023-05-18 15:34: Train Epoch 13: 160/167 Loss: 20.754784
2023-05-18 15:34: **********Train Epoch 13: averaged Loss: 20.291841, tf_ratio: 1.000000
2023-05-18 15:34: **********Val Epoch 13: average Loss: 21.169528
2023-05-18 15:34: Train Epoch 14: 0/167 Loss: 19.051491
2023-05-18 15:34: Train Epoch 14: 20/167 Loss: 19.894617
2023-05-18 15:34: Train Epoch 14: 40/167 Loss: 20.940014
2023-05-18 15:34: Train Epoch 14: 60/167 Loss: 20.832638
2023-05-18 15:34: Train Epoch 14: 80/167 Loss: 19.059685
2023-05-18 15:34: Train Epoch 14: 100/167 Loss: 23.329468
2023-05-18 15:35: Train Epoch 14: 120/167 Loss: 21.390045
2023-05-18 15:35: Train Epoch 14: 140/167 Loss: 19.484400
2023-05-18 15:35: Train Epoch 14: 160/167 Loss: 20.147053
2023-05-18 15:35: **********Train Epoch 14: averaged Loss: 20.236694, tf_ratio: 1.000000
2023-05-18 15:35: **********Val Epoch 14: average Loss: 20.465051
2023-05-18 15:35: ******Current best model saved:model_para/PEMSD8/epoch_14.pth!
2023-05-18 15:35: Train Epoch 15: 0/167 Loss: 19.098875
2023-05-18 15:35: Train Epoch 15: 20/167 Loss: 20.718687
2023-05-18 15:35: Train Epoch 15: 40/167 Loss: 19.427141
2023-05-18 15:35: Train Epoch 15: 60/167 Loss: 19.821342
2023-05-18 15:35: Train Epoch 15: 80/167 Loss: 20.258495
2023-05-18 15:35: Train Epoch 15: 100/167 Loss: 20.466625
2023-05-18 15:35: Train Epoch 15: 120/167 Loss: 20.328808
2023-05-18 15:35: Train Epoch 15: 140/167 Loss: 19.606203
2023-05-18 15:35: Train Epoch 15: 160/167 Loss: 20.821533
2023-05-18 15:35: **********Train Epoch 15: averaged Loss: 20.182264, tf_ratio: 1.000000
2023-05-18 15:35: **********Val Epoch 15: average Loss: 20.872753
2023-05-18 15:35: Train Epoch 16: 0/167 Loss: 20.398603
2023-05-18 15:35: Train Epoch 16: 20/167 Loss: 20.503153
2023-05-18 15:35: Train Epoch 16: 40/167 Loss: 19.223217
2023-05-18 15:35: Train Epoch 16: 60/167 Loss: 19.667540
2023-05-18 15:35: Train Epoch 16: 80/167 Loss: 20.987362
2023-05-18 15:35: Train Epoch 16: 100/167 Loss: 21.049314
2023-05-18 15:35: Train Epoch 16: 120/167 Loss: 18.972040
2023-05-18 15:35: Train Epoch 16: 140/167 Loss: 21.528627
2023-05-18 15:35: Train Epoch 16: 160/167 Loss: 18.598328
2023-05-18 15:35: **********Train Epoch 16: averaged Loss: 19.988880, tf_ratio: 1.000000
2023-05-18 15:35: **********Val Epoch 16: average Loss: 20.172239
2023-05-18 15:35: ******Current best model saved:model_para/PEMSD8/epoch_16.pth!
2023-05-18 15:35: Train Epoch 17: 0/167 Loss: 20.133541
2023-05-18 15:35: Train Epoch 17: 20/167 Loss: 20.654318
2023-05-18 15:35: Train Epoch 17: 40/167 Loss: 20.238089
2023-05-18 15:35: Train Epoch 17: 60/167 Loss: 19.639093
2023-05-18 15:35: Train Epoch 17: 80/167 Loss: 21.477779
2023-05-18 15:35: Train Epoch 17: 100/167 Loss: 19.683170
2023-05-18 15:35: Train Epoch 17: 120/167 Loss: 19.527632
2023-05-18 15:35: Train Epoch 17: 140/167 Loss: 20.727943
2023-05-18 15:35: Train Epoch 17: 160/167 Loss: 21.493450
2023-05-18 15:35: **********Train Epoch 17: averaged Loss: 19.930022, tf_ratio: 1.000000
2023-05-18 15:36: **********Val Epoch 17: average Loss: 20.425837
2023-05-18 15:36: Train Epoch 18: 0/167 Loss: 20.204157
2023-05-18 15:36: Train Epoch 18: 20/167 Loss: 18.750391
2023-05-18 15:36: Train Epoch 18: 40/167 Loss: 19.780123
2023-05-18 15:36: Train Epoch 18: 60/167 Loss: 19.440512
2023-05-18 15:36: Train Epoch 18: 80/167 Loss: 19.935514
2023-05-18 15:36: Train Epoch 18: 100/167 Loss: 21.449032
2023-05-18 15:36: Train Epoch 18: 120/167 Loss: 21.921278
2023-05-18 15:36: Train Epoch 18: 140/167 Loss: 18.813959
2023-05-18 15:36: Train Epoch 18: 160/167 Loss: 20.377766
2023-05-18 15:36: **********Train Epoch 18: averaged Loss: 19.970739, tf_ratio: 1.000000
2023-05-18 15:36: **********Val Epoch 18: average Loss: 20.792437
2023-05-18 15:36: Train Epoch 19: 0/167 Loss: 21.088915
2023-05-18 15:36: Train Epoch 19: 20/167 Loss: 21.080320
2023-05-18 15:36: Train Epoch 19: 40/167 Loss: 21.295177
2023-05-18 15:36: Train Epoch 19: 60/167 Loss: 20.134882
2023-05-18 15:36: Train Epoch 19: 80/167 Loss: 20.360319
2023-05-18 15:36: Train Epoch 19: 100/167 Loss: 20.967354
2023-05-18 15:36: Train Epoch 19: 120/167 Loss: 19.847321
2023-05-18 15:36: Train Epoch 19: 140/167 Loss: 20.890877
2023-05-18 15:36: Train Epoch 19: 160/167 Loss: 19.352976
2023-05-18 15:36: **********Train Epoch 19: averaged Loss: 20.006418, tf_ratio: 1.000000
2023-05-18 15:36: **********Val Epoch 19: average Loss: 20.042414
2023-05-18 15:36: ******Current best model saved:model_para/PEMSD8/epoch_19.pth!
2023-05-18 15:36: Train Epoch 20: 0/167 Loss: 18.355844
2023-05-18 15:36: Train Epoch 20: 20/167 Loss: 19.184673
2023-05-18 15:36: Train Epoch 20: 40/167 Loss: 20.493992
2023-05-18 15:36: Train Epoch 20: 60/167 Loss: 21.846025
2023-05-18 15:36: Train Epoch 20: 80/167 Loss: 19.930693
2023-05-18 15:36: Train Epoch 20: 100/167 Loss: 18.902744
2023-05-18 15:36: Train Epoch 20: 120/167 Loss: 19.016129
2023-05-18 15:36: Train Epoch 20: 140/167 Loss: 20.148178
2023-05-18 15:36: Train Epoch 20: 160/167 Loss: 20.424589
2023-05-18 15:36: **********Train Epoch 20: averaged Loss: 19.878830, tf_ratio: 1.000000
2023-05-18 15:36: **********Val Epoch 20: average Loss: 19.954571
2023-05-18 15:36: ******Current best model saved:model_para/PEMSD8/epoch_20.pth!
2023-05-18 15:36: Train Epoch 21: 0/167 Loss: 20.119576
2023-05-18 15:36: Train Epoch 21: 20/167 Loss: 18.959709
2023-05-18 15:36: Train Epoch 21: 40/167 Loss: 21.649775
2023-05-18 15:36: Train Epoch 21: 60/167 Loss: 21.760691
2023-05-18 15:37: Train Epoch 21: 80/167 Loss: 20.337717
2023-05-18 15:37: Train Epoch 21: 100/167 Loss: 17.987864
2023-05-18 15:37: Train Epoch 21: 120/167 Loss: 20.145966
2023-05-18 15:37: Train Epoch 21: 140/167 Loss: 21.332878
2023-05-18 15:37: Train Epoch 21: 160/167 Loss: 20.438383
2023-05-18 15:37: **********Train Epoch 21: averaged Loss: 20.200114, tf_ratio: 1.000000
2023-05-18 15:37: **********Val Epoch 21: average Loss: 21.047487
2023-05-18 15:37: Train Epoch 22: 0/167 Loss: 20.029623
2023-05-18 15:37: Train Epoch 22: 20/167 Loss: 20.219305
2023-05-18 15:37: Train Epoch 22: 40/167 Loss: 19.835804
2023-05-18 15:37: Train Epoch 22: 60/167 Loss: 18.360159
2023-05-18 15:37: Train Epoch 22: 80/167 Loss: 17.481228
2023-05-18 15:37: Train Epoch 22: 100/167 Loss: 19.383074
2023-05-18 15:37: Train Epoch 22: 120/167 Loss: 20.402864
2023-05-18 15:37: Train Epoch 22: 140/167 Loss: 22.072052
2023-05-18 15:37: Train Epoch 22: 160/167 Loss: 19.620304
2023-05-18 15:37: **********Train Epoch 22: averaged Loss: 19.909716, tf_ratio: 1.000000
2023-05-18 15:37: **********Val Epoch 22: average Loss: 20.201574
2023-05-18 15:37: Train Epoch 23: 0/167 Loss: 20.014317
2023-05-18 15:37: Train Epoch 23: 20/167 Loss: 19.549303
2023-05-18 15:37: Train Epoch 23: 40/167 Loss: 19.257530
2023-05-18 15:37: Train Epoch 23: 60/167 Loss: 21.735706
2023-05-18 15:37: Train Epoch 23: 80/167 Loss: 19.114904
2023-05-18 15:37: Train Epoch 23: 100/167 Loss: 19.253735
2023-05-18 15:37: Train Epoch 23: 120/167 Loss: 20.693237
2023-05-18 15:37: Train Epoch 23: 140/167 Loss: 19.475777
2023-05-18 15:37: Train Epoch 23: 160/167 Loss: 19.833578
2023-05-18 15:37: **********Train Epoch 23: averaged Loss: 19.818632, tf_ratio: 1.000000
2023-05-18 15:37: **********Val Epoch 23: average Loss: 20.003936
2023-05-18 15:37: Train Epoch 24: 0/167 Loss: 19.541025
2023-05-18 15:37: Train Epoch 24: 20/167 Loss: 21.198032
2023-05-18 15:37: Train Epoch 24: 40/167 Loss: 21.676638
2023-05-18 15:37: Train Epoch 24: 60/167 Loss: 21.633497
2023-05-18 15:37: Train Epoch 24: 80/167 Loss: 19.338387
2023-05-18 15:37: Train Epoch 24: 100/167 Loss: 22.140049
2023-05-18 15:37: Train Epoch 24: 120/167 Loss: 18.895275
2023-05-18 15:37: Train Epoch 24: 140/167 Loss: 18.787470
2023-05-18 15:38: Train Epoch 24: 160/167 Loss: 19.832710
2023-05-18 15:38: **********Train Epoch 24: averaged Loss: 19.703621, tf_ratio: 1.000000
2023-05-18 15:38: **********Val Epoch 24: average Loss: 20.741901
2023-05-18 15:38: Train Epoch 25: 0/167 Loss: 21.492834
2023-05-18 15:38: Train Epoch 25: 20/167 Loss: 19.600792
2023-05-18 15:38: Train Epoch 25: 40/167 Loss: 20.677555
2023-05-18 15:38: Train Epoch 25: 60/167 Loss: 20.346193
2023-05-18 15:38: Train Epoch 25: 80/167 Loss: 20.197788
2023-05-18 15:38: Train Epoch 25: 100/167 Loss: 20.181152
2023-05-18 15:38: Train Epoch 25: 120/167 Loss: 20.145470
2023-05-18 15:38: Train Epoch 25: 140/167 Loss: 19.338501
2023-05-18 15:38: Train Epoch 25: 160/167 Loss: 18.984343
2023-05-18 15:38: **********Train Epoch 25: averaged Loss: 19.624632, tf_ratio: 1.000000
2023-05-18 15:38: **********Val Epoch 25: average Loss: 19.632280
2023-05-18 15:38: ******Current best model saved:model_para/PEMSD8/epoch_25.pth!
2023-05-18 15:38: Train Epoch 26: 0/167 Loss: 19.121397
2023-05-18 15:38: Train Epoch 26: 20/167 Loss: 19.647848
2023-05-18 15:38: Train Epoch 26: 40/167 Loss: 19.198601
2023-05-18 15:38: Train Epoch 26: 60/167 Loss: 18.987118
2023-05-18 15:38: Train Epoch 26: 80/167 Loss: 20.152754
2023-05-18 15:38: Train Epoch 26: 100/167 Loss: 19.622761
2023-05-18 15:38: Train Epoch 26: 120/167 Loss: 19.933762
2023-05-18 15:38: Train Epoch 26: 140/167 Loss: 20.257833
2023-05-18 15:38: Train Epoch 26: 160/167 Loss: 20.110376
2023-05-18 15:38: **********Train Epoch 26: averaged Loss: 19.583495, tf_ratio: 1.000000
2023-05-18 15:38: **********Val Epoch 26: average Loss: 19.665369
2023-05-18 15:38: Train Epoch 27: 0/167 Loss: 18.685984
2023-05-18 15:38: Train Epoch 27: 20/167 Loss: 20.337776
2023-05-18 15:38: Train Epoch 27: 40/167 Loss: 19.734207
2023-05-18 15:38: Train Epoch 27: 60/167 Loss: 19.816475
2023-05-18 15:38: Train Epoch 27: 80/167 Loss: 18.074408
2023-05-18 15:38: Train Epoch 27: 100/167 Loss: 18.928268
2023-05-18 15:38: Train Epoch 27: 120/167 Loss: 19.099463
2023-05-18 15:38: Train Epoch 27: 140/167 Loss: 20.758965
2023-05-18 15:38: Train Epoch 27: 160/167 Loss: 19.449566
2023-05-18 15:38: **********Train Epoch 27: averaged Loss: 19.643052, tf_ratio: 1.000000
2023-05-18 15:38: **********Val Epoch 27: average Loss: 19.945306
2023-05-18 15:38: Train Epoch 28: 0/167 Loss: 20.010410
2023-05-18 15:38: Train Epoch 28: 20/167 Loss: 18.564878
2023-05-18 15:39: Train Epoch 28: 40/167 Loss: 19.794897
2023-05-18 15:39: Train Epoch 28: 60/167 Loss: 20.086657
2023-05-18 15:39: Train Epoch 28: 80/167 Loss: 21.390959
2023-05-18 15:39: Train Epoch 28: 100/167 Loss: 18.677179
2023-05-18 15:39: Train Epoch 28: 120/167 Loss: 20.785372
2023-05-18 15:39: Train Epoch 28: 140/167 Loss: 18.715006
2023-05-18 15:39: Train Epoch 28: 160/167 Loss: 18.534094
2023-05-18 15:39: **********Train Epoch 28: averaged Loss: 19.649646, tf_ratio: 1.000000
2023-05-18 15:39: **********Val Epoch 28: average Loss: 19.749742
2023-05-18 15:39: Train Epoch 29: 0/167 Loss: 19.719288
2023-05-18 15:39: Train Epoch 29: 20/167 Loss: 19.615595
2023-05-18 15:39: Train Epoch 29: 40/167 Loss: 19.843784
2023-05-18 15:39: Train Epoch 29: 60/167 Loss: 18.581036
2023-05-18 15:39: Train Epoch 29: 80/167 Loss: 20.773071
2023-05-18 15:39: Train Epoch 29: 100/167 Loss: 20.373251
2023-05-18 15:39: Train Epoch 29: 120/167 Loss: 18.367123
2023-05-18 15:39: Train Epoch 29: 140/167 Loss: 20.029066
2023-05-18 15:39: Train Epoch 29: 160/167 Loss: 19.202333
2023-05-18 15:39: **********Train Epoch 29: averaged Loss: 19.717059, tf_ratio: 1.000000
2023-05-18 15:39: **********Val Epoch 29: average Loss: 20.591541
2023-05-18 15:39: Train Epoch 30: 0/167 Loss: 19.872894
2023-05-18 15:39: Train Epoch 30: 20/167 Loss: 18.305428
2023-05-18 15:39: Train Epoch 30: 40/167 Loss: 17.516878
2023-05-18 15:39: Train Epoch 30: 60/167 Loss: 20.496891
2023-05-18 15:39: Train Epoch 30: 80/167 Loss: 19.665840
2023-05-18 15:39: Train Epoch 30: 100/167 Loss: 19.209402
2023-05-18 15:39: Train Epoch 30: 120/167 Loss: 18.534941
2023-05-18 15:39: Train Epoch 30: 140/167 Loss: 20.073658
2023-05-18 15:39: Train Epoch 30: 160/167 Loss: 19.450480
2023-05-18 15:39: **********Train Epoch 30: averaged Loss: 19.579501, tf_ratio: 1.000000
2023-05-18 15:39: **********Val Epoch 30: average Loss: 19.664824
2023-05-18 15:39: Train Epoch 31: 0/167 Loss: 19.792543
2023-05-18 15:39: Train Epoch 31: 20/167 Loss: 20.635973
2023-05-18 15:39: Train Epoch 31: 40/167 Loss: 20.267147
2023-05-18 15:39: Train Epoch 31: 60/167 Loss: 19.049889
2023-05-18 15:39: Train Epoch 31: 80/167 Loss: 19.295252
2023-05-18 15:39: Train Epoch 31: 100/167 Loss: 20.284462
2023-05-18 15:40: Train Epoch 31: 120/167 Loss: 18.112915
2023-05-18 15:40: Train Epoch 31: 140/167 Loss: 20.833660
2023-05-18 15:40: Train Epoch 31: 160/167 Loss: 19.091625
2023-05-18 15:40: **********Train Epoch 31: averaged Loss: 19.514654, tf_ratio: 1.000000
2023-05-18 15:40: **********Val Epoch 31: average Loss: 19.847917
2023-05-18 15:40: Train Epoch 32: 0/167 Loss: 17.840048
2023-05-18 15:40: Train Epoch 32: 20/167 Loss: 18.240179
2023-05-18 15:40: Train Epoch 32: 40/167 Loss: 18.886402
2023-05-18 15:40: Train Epoch 32: 60/167 Loss: 19.516779
2023-05-18 15:40: Train Epoch 32: 80/167 Loss: 18.993410
2023-05-18 15:40: Train Epoch 32: 100/167 Loss: 19.212254
2023-05-18 15:40: Train Epoch 32: 120/167 Loss: 19.472681
2023-05-18 15:40: Train Epoch 32: 140/167 Loss: 18.935425
2023-05-18 15:40: Train Epoch 32: 160/167 Loss: 19.784224
2023-05-18 15:40: **********Train Epoch 32: averaged Loss: 19.408865, tf_ratio: 1.000000
2023-05-18 15:40: **********Val Epoch 32: average Loss: 20.336652
2023-05-18 15:40: Train Epoch 33: 0/167 Loss: 20.892296
2023-05-18 15:40: Train Epoch 33: 20/167 Loss: 19.885246
2023-05-18 15:40: Train Epoch 33: 40/167 Loss: 18.502493
2023-05-18 15:40: Train Epoch 33: 60/167 Loss: 20.011307
2023-05-18 15:40: Train Epoch 33: 80/167 Loss: 19.619858
2023-05-18 15:40: Train Epoch 33: 100/167 Loss: 20.668568
2023-05-18 15:40: Train Epoch 33: 120/167 Loss: 20.593878
2023-05-18 15:40: Train Epoch 33: 140/167 Loss: 19.931498
2023-05-18 15:40: Train Epoch 33: 160/167 Loss: 19.888866
2023-05-18 15:40: **********Train Epoch 33: averaged Loss: 19.571133, tf_ratio: 1.000000
2023-05-18 15:40: **********Val Epoch 33: average Loss: 19.772092
2023-05-18 15:40: Train Epoch 34: 0/167 Loss: 18.802179
2023-05-18 15:40: Train Epoch 34: 20/167 Loss: 18.396776
2023-05-18 15:40: Train Epoch 34: 40/167 Loss: 20.468790
2023-05-18 15:40: Train Epoch 34: 60/167 Loss: 19.047548
2023-05-18 15:40: Train Epoch 34: 80/167 Loss: 17.648064
2023-05-18 15:40: Train Epoch 34: 100/167 Loss: 19.819717
2023-05-18 15:40: Train Epoch 34: 120/167 Loss: 19.093367
2023-05-18 15:40: Train Epoch 34: 140/167 Loss: 17.826183
2023-05-18 15:40: Train Epoch 34: 160/167 Loss: 20.493528
2023-05-18 15:40: **********Train Epoch 34: averaged Loss: 19.473401, tf_ratio: 1.000000
2023-05-18 15:40: **********Val Epoch 34: average Loss: 19.736176
2023-05-18 15:40: Train Epoch 35: 0/167 Loss: 20.119539
2023-05-18 15:41: Train Epoch 35: 20/167 Loss: 21.655308
2023-05-18 15:41: Train Epoch 35: 40/167 Loss: 20.442432
2023-05-18 15:41: Train Epoch 35: 60/167 Loss: 18.014223
2023-05-18 15:41: Train Epoch 35: 80/167 Loss: 19.799732
2023-05-18 15:41: Train Epoch 35: 100/167 Loss: 19.309715
2023-05-18 15:41: Train Epoch 35: 120/167 Loss: 20.118029
2023-05-18 15:41: Train Epoch 35: 140/167 Loss: 19.456001
2023-05-18 15:41: Train Epoch 35: 160/167 Loss: 20.493452
2023-05-18 15:41: **********Train Epoch 35: averaged Loss: 19.549781, tf_ratio: 1.000000
2023-05-18 15:41: **********Val Epoch 35: average Loss: 19.802213
2023-05-18 15:41: Train Epoch 36: 0/167 Loss: 18.064657
2023-05-18 15:41: Train Epoch 36: 20/167 Loss: 19.122461
2023-05-18 15:41: Train Epoch 36: 40/167 Loss: 19.841053
2023-05-18 15:41: Train Epoch 36: 60/167 Loss: 20.947332
2023-05-18 15:41: Train Epoch 36: 80/167 Loss: 19.664785
2023-05-18 15:41: Train Epoch 36: 100/167 Loss: 19.730431
2023-05-18 15:41: Train Epoch 36: 120/167 Loss: 19.708033
2023-05-18 15:41: Train Epoch 36: 140/167 Loss: 20.317385
2023-05-18 15:41: Train Epoch 36: 160/167 Loss: 21.183733
2023-05-18 15:41: **********Train Epoch 36: averaged Loss: 19.529718, tf_ratio: 1.000000
2023-05-18 15:41: **********Val Epoch 36: average Loss: 20.664707
2023-05-18 15:41: Train Epoch 37: 0/167 Loss: 22.535980
2023-05-18 15:41: Train Epoch 37: 20/167 Loss: 17.948212
2023-05-18 15:41: Train Epoch 37: 40/167 Loss: 20.160673
2023-05-18 15:41: Train Epoch 37: 60/167 Loss: 19.006718
2023-05-18 15:41: Train Epoch 37: 80/167 Loss: 19.299454
2023-05-18 15:41: Train Epoch 37: 100/167 Loss: 20.905914
2023-05-18 15:41: Train Epoch 37: 120/167 Loss: 20.211149
2023-05-18 15:41: Train Epoch 37: 140/167 Loss: 18.586502
2023-05-18 15:41: Train Epoch 37: 160/167 Loss: 18.200342
2023-05-18 15:41: **********Train Epoch 37: averaged Loss: 19.518796, tf_ratio: 1.000000
2023-05-18 15:41: **********Val Epoch 37: average Loss: 19.562917
2023-05-18 15:41: ******Current best model saved:model_para/PEMSD8/epoch_37.pth!
2023-05-18 15:41: Train Epoch 38: 0/167 Loss: 20.318552
2023-05-18 15:41: Train Epoch 38: 20/167 Loss: 20.574625
2023-05-18 15:41: Train Epoch 38: 40/167 Loss: 19.778887
2023-05-18 15:41: Train Epoch 38: 60/167 Loss: 19.239933
2023-05-18 15:41: Train Epoch 38: 80/167 Loss: 17.786018
2023-05-18 15:42: Train Epoch 38: 100/167 Loss: 18.789358
2023-05-18 15:42: Train Epoch 38: 120/167 Loss: 18.735720
2023-05-18 15:42: Train Epoch 38: 140/167 Loss: 19.213120
2023-05-18 15:42: Train Epoch 38: 160/167 Loss: 19.699337
2023-05-18 15:42: **********Train Epoch 38: averaged Loss: 19.331024, tf_ratio: 1.000000
2023-05-18 15:42: **********Val Epoch 38: average Loss: 19.521323
2023-05-18 15:42: ******Current best model saved:model_para/PEMSD8/epoch_38.pth!
2023-05-18 15:42: Train Epoch 39: 0/167 Loss: 19.986502
2023-05-18 15:42: Train Epoch 39: 20/167 Loss: 19.196398
2023-05-18 15:42: Train Epoch 39: 40/167 Loss: 17.817936
2023-05-18 15:42: Train Epoch 39: 60/167 Loss: 18.172638
2023-05-18 15:42: Train Epoch 39: 80/167 Loss: 18.350082
2023-05-18 15:42: Train Epoch 39: 100/167 Loss: 19.096327
2023-05-18 15:42: Train Epoch 39: 120/167 Loss: 19.379057
2023-05-18 15:42: Train Epoch 39: 140/167 Loss: 19.528866
2023-05-18 15:42: Train Epoch 39: 160/167 Loss: 18.310923
2023-05-18 15:42: **********Train Epoch 39: averaged Loss: 19.367224, tf_ratio: 1.000000
2023-05-18 15:42: **********Val Epoch 39: average Loss: 19.912041
2023-05-18 15:42: Train Epoch 40: 0/167 Loss: 19.126554
2023-05-18 15:42: Train Epoch 40: 20/167 Loss: 17.927860
2023-05-18 15:42: Train Epoch 40: 40/167 Loss: 18.385481
2023-05-18 15:42: Train Epoch 40: 60/167 Loss: 18.757641
2023-05-18 15:42: Train Epoch 40: 80/167 Loss: 20.002222
2023-05-18 15:42: Train Epoch 40: 100/167 Loss: 19.431684
2023-05-18 15:42: Train Epoch 40: 120/167 Loss: 20.101776
2023-05-18 15:42: Train Epoch 40: 140/167 Loss: 18.623171
2023-05-18 15:42: Train Epoch 40: 160/167 Loss: 19.422958
2023-05-18 15:42: **********Train Epoch 40: averaged Loss: 19.461021, tf_ratio: 1.000000
2023-05-18 15:42: **********Val Epoch 40: average Loss: 19.382572
2023-05-18 15:42: ******Current best model saved:model_para/PEMSD8/epoch_40.pth!
2023-05-18 15:42: Train Epoch 41: 0/167 Loss: 17.060152
2023-05-18 15:42: Train Epoch 41: 20/167 Loss: 18.264196
2023-05-18 15:42: Train Epoch 41: 40/167 Loss: 19.763029
2023-05-18 15:42: Train Epoch 41: 60/167 Loss: 19.961418
2023-05-18 15:42: Train Epoch 41: 80/167 Loss: 18.671230
2023-05-18 15:42: Train Epoch 41: 100/167 Loss: 17.994778
2023-05-18 15:42: Train Epoch 41: 120/167 Loss: 18.858501
2023-05-18 15:42: Train Epoch 41: 140/167 Loss: 18.867111
2023-05-18 15:43: Train Epoch 41: 160/167 Loss: 22.886208
2023-05-18 15:43: **********Train Epoch 41: averaged Loss: 19.328295, tf_ratio: 1.000000
2023-05-18 15:43: **********Val Epoch 41: average Loss: 19.815841
2023-05-18 15:43: Train Epoch 42: 0/167 Loss: 19.758434
2023-05-18 15:43: Train Epoch 42: 20/167 Loss: 18.829937
2023-05-18 15:43: Train Epoch 42: 40/167 Loss: 19.332117
2023-05-18 15:43: Train Epoch 42: 60/167 Loss: 18.768345
2023-05-18 15:43: Train Epoch 42: 80/167 Loss: 18.884033
2023-05-18 15:43: Train Epoch 42: 100/167 Loss: 18.721119
2023-05-18 15:43: Train Epoch 42: 120/167 Loss: 19.935265
2023-05-18 15:43: Train Epoch 42: 140/167 Loss: 18.071051
2023-05-18 15:43: Train Epoch 42: 160/167 Loss: 21.284121
2023-05-18 15:43: **********Train Epoch 42: averaged Loss: 19.143565, tf_ratio: 1.000000
2023-05-18 15:43: **********Val Epoch 42: average Loss: 19.559097
2023-05-18 15:43: Train Epoch 43: 0/167 Loss: 19.079042
2023-05-18 15:43: Train Epoch 43: 20/167 Loss: 19.041452
2023-05-18 15:43: Train Epoch 43: 40/167 Loss: 18.468586
2023-05-18 15:43: Train Epoch 43: 60/167 Loss: 20.522186
2023-05-18 15:43: Train Epoch 43: 80/167 Loss: 19.199741
2023-05-18 15:43: Train Epoch 43: 100/167 Loss: 17.794773
2023-05-18 15:43: Train Epoch 43: 120/167 Loss: 19.003500
2023-05-18 15:43: Train Epoch 43: 140/167 Loss: 19.510225
2023-05-18 15:43: Train Epoch 43: 160/167 Loss: 18.610313
2023-05-18 15:43: **********Train Epoch 43: averaged Loss: 19.276678, tf_ratio: 1.000000
2023-05-18 15:43: **********Val Epoch 43: average Loss: 19.542266
2023-05-18 15:43: Train Epoch 44: 0/167 Loss: 20.207787
2023-05-18 15:43: Train Epoch 44: 20/167 Loss: 18.830704
2023-05-18 15:43: Train Epoch 44: 40/167 Loss: 18.689930
2023-05-18 15:43: Train Epoch 44: 60/167 Loss: 18.703720
2023-05-18 15:43: Train Epoch 44: 80/167 Loss: 19.404060
2023-05-18 15:43: Train Epoch 44: 100/167 Loss: 18.359987
2023-05-18 15:43: Train Epoch 44: 120/167 Loss: 20.073221
2023-05-18 15:43: Train Epoch 44: 140/167 Loss: 18.059069
2023-05-18 15:43: Train Epoch 44: 160/167 Loss: 18.598736
2023-05-18 15:43: **********Train Epoch 44: averaged Loss: 19.182985, tf_ratio: 1.000000
2023-05-18 15:43: **********Val Epoch 44: average Loss: 21.274202
2023-05-18 15:43: Train Epoch 45: 0/167 Loss: 21.785177
2023-05-18 15:43: Train Epoch 45: 20/167 Loss: 19.023430
2023-05-18 15:43: Train Epoch 45: 40/167 Loss: 19.726427
2023-05-18 15:44: Train Epoch 45: 60/167 Loss: 19.375797
2023-05-18 15:44: Train Epoch 45: 80/167 Loss: 19.293129
2023-05-18 15:44: Train Epoch 45: 100/167 Loss: 19.866369
2023-05-18 15:44: Train Epoch 45: 120/167 Loss: 18.040421
2023-05-18 15:44: Train Epoch 45: 140/167 Loss: 18.686167
2023-05-18 15:44: Train Epoch 45: 160/167 Loss: 17.981365
2023-05-18 15:44: **********Train Epoch 45: averaged Loss: 19.232243, tf_ratio: 1.000000
2023-05-18 15:44: **********Val Epoch 45: average Loss: 19.265501
2023-05-18 15:44: ******Current best model saved:model_para/PEMSD8/epoch_45.pth!
2023-05-18 15:44: Train Epoch 46: 0/167 Loss: 19.598925
2023-05-18 15:44: Train Epoch 46: 20/167 Loss: 19.058514
2023-05-18 15:44: Train Epoch 46: 40/167 Loss: 18.862703
2023-05-18 15:44: Train Epoch 46: 60/167 Loss: 18.260403
2023-05-18 15:44: Train Epoch 46: 80/167 Loss: 19.438633
2023-05-18 15:44: Train Epoch 46: 100/167 Loss: 18.416691
2023-05-18 15:44: Train Epoch 46: 120/167 Loss: 19.859779
2023-05-18 15:44: Train Epoch 46: 140/167 Loss: 20.435635
2023-05-18 15:44: Train Epoch 46: 160/167 Loss: 18.302942
2023-05-18 15:44: **********Train Epoch 46: averaged Loss: 19.148735, tf_ratio: 1.000000
2023-05-18 15:44: **********Val Epoch 46: average Loss: 19.205719
2023-05-18 15:44: ******Current best model saved:model_para/PEMSD8/epoch_46.pth!
2023-05-18 15:44: Train Epoch 47: 0/167 Loss: 19.620590
2023-05-18 15:44: Train Epoch 47: 20/167 Loss: 18.946718
2023-05-18 15:44: Train Epoch 47: 40/167 Loss: 18.704493
2023-05-18 15:44: Train Epoch 47: 60/167 Loss: 19.306126
2023-05-18 15:44: Train Epoch 47: 80/167 Loss: 17.972807
2023-05-18 15:44: Train Epoch 47: 100/167 Loss: 19.188528
2023-05-18 15:44: Train Epoch 47: 120/167 Loss: 19.824959
2023-05-18 15:44: Train Epoch 47: 140/167 Loss: 19.289921
2023-05-18 15:44: Train Epoch 47: 160/167 Loss: 19.863155
2023-05-18 15:44: **********Train Epoch 47: averaged Loss: 19.086631, tf_ratio: 1.000000
2023-05-18 15:44: **********Val Epoch 47: average Loss: 19.382965
2023-05-18 15:44: Train Epoch 48: 0/167 Loss: 19.517635
2023-05-18 15:44: Train Epoch 48: 20/167 Loss: 19.343025
2023-05-18 15:44: Train Epoch 48: 40/167 Loss: 17.722301
2023-05-18 15:44: Train Epoch 48: 60/167 Loss: 20.521397
2023-05-18 15:44: Train Epoch 48: 80/167 Loss: 19.856173
2023-05-18 15:44: Train Epoch 48: 100/167 Loss: 19.535480
2023-05-18 15:45: Train Epoch 48: 120/167 Loss: 18.638317
2023-05-18 15:45: Train Epoch 48: 140/167 Loss: 19.141077
2023-05-18 15:45: Train Epoch 48: 160/167 Loss: 19.419233
2023-05-18 15:45: **********Train Epoch 48: averaged Loss: 19.036674, tf_ratio: 1.000000
2023-05-18 15:45: **********Val Epoch 48: average Loss: 19.511715
2023-05-18 15:45: Train Epoch 49: 0/167 Loss: 19.527533
2023-05-18 15:45: Train Epoch 49: 20/167 Loss: 18.944717
2023-05-18 15:45: Train Epoch 49: 40/167 Loss: 19.306673
2023-05-18 15:45: Train Epoch 49: 60/167 Loss: 17.703041
2023-05-18 15:45: Train Epoch 49: 80/167 Loss: 18.259598
2023-05-18 15:45: Train Epoch 49: 100/167 Loss: 19.016943
2023-05-18 15:45: Train Epoch 49: 120/167 Loss: 16.762697
2023-05-18 15:45: Train Epoch 49: 140/167 Loss: 18.979982
2023-05-18 15:45: Train Epoch 49: 160/167 Loss: 19.901299
2023-05-18 15:45: **********Train Epoch 49: averaged Loss: 18.936841, tf_ratio: 1.000000
2023-05-18 15:45: **********Val Epoch 49: average Loss: 19.643154
2023-05-18 15:45: Train Epoch 50: 0/167 Loss: 20.998304
2023-05-18 15:45: Train Epoch 50: 20/167 Loss: 18.994019
2023-05-18 15:45: Train Epoch 50: 40/167 Loss: 19.289806
2023-05-18 15:45: Train Epoch 50: 60/167 Loss: 19.435022
2023-05-18 15:45: Train Epoch 50: 80/167 Loss: 18.247267
2023-05-18 15:45: Train Epoch 50: 100/167 Loss: 18.952272
2023-05-18 15:45: Train Epoch 50: 120/167 Loss: 17.623901
2023-05-18 15:45: Train Epoch 50: 140/167 Loss: 18.476583
2023-05-18 15:45: Train Epoch 50: 160/167 Loss: 18.211643
2023-05-18 15:45: **********Train Epoch 50: averaged Loss: 18.908803, tf_ratio: 1.000000
2023-05-18 15:45: **********Val Epoch 50: average Loss: 19.116075
2023-05-18 15:45: ******Current best model saved:model_para/PEMSD8/epoch_50.pth!
2023-05-18 15:45: Train Epoch 51: 0/167 Loss: 19.350266
2023-05-18 15:45: Train Epoch 51: 20/167 Loss: 19.908051
2023-05-18 15:45: Train Epoch 51: 40/167 Loss: 19.259138
2023-05-18 15:45: Train Epoch 51: 60/167 Loss: 19.581404
2023-05-18 15:45: Train Epoch 51: 80/167 Loss: 19.314642
2023-05-18 15:45: Train Epoch 51: 100/167 Loss: 18.427858
2023-05-18 15:45: Train Epoch 51: 120/167 Loss: 18.715033
2023-05-18 15:45: Train Epoch 51: 140/167 Loss: 18.057184
2023-05-18 15:45: Train Epoch 51: 160/167 Loss: 18.850756
2023-05-18 15:45: **********Train Epoch 51: averaged Loss: 18.914668, tf_ratio: 1.000000
2023-05-18 15:45: **********Val Epoch 51: average Loss: 19.084293
2023-05-18 15:45: ******Current best model saved:model_para/PEMSD8/epoch_51.pth!
2023-05-18 15:45: Train Epoch 52: 0/167 Loss: 17.948868
2023-05-18 15:46: Train Epoch 52: 20/167 Loss: 18.962164
2023-05-18 15:46: Train Epoch 52: 40/167 Loss: 17.168617
2023-05-18 15:46: Train Epoch 52: 60/167 Loss: 19.514002
2023-05-18 15:46: Train Epoch 52: 80/167 Loss: 18.553925
2023-05-18 15:46: Train Epoch 52: 100/167 Loss: 18.680229
2023-05-18 15:46: Train Epoch 52: 120/167 Loss: 17.704370
2023-05-18 15:46: Train Epoch 52: 140/167 Loss: 19.725946
2023-05-18 15:46: Train Epoch 52: 160/167 Loss: 19.327206
2023-05-18 15:46: **********Train Epoch 52: averaged Loss: 18.826964, tf_ratio: 1.000000
2023-05-18 15:46: **********Val Epoch 52: average Loss: 18.911505
2023-05-18 15:46: ******Current best model saved:model_para/PEMSD8/epoch_52.pth!
2023-05-18 15:46: Train Epoch 53: 0/167 Loss: 19.861774
2023-05-18 15:46: Train Epoch 53: 20/167 Loss: 18.043180
2023-05-18 15:46: Train Epoch 53: 40/167 Loss: 19.580654
2023-05-18 15:46: Train Epoch 53: 60/167 Loss: 18.990871
2023-05-18 15:46: Train Epoch 53: 80/167 Loss: 17.999722
2023-05-18 15:46: Train Epoch 53: 100/167 Loss: 18.507444
2023-05-18 15:46: Train Epoch 53: 120/167 Loss: 18.118870
2023-05-18 15:46: Train Epoch 53: 140/167 Loss: 17.241718
2023-05-18 15:46: Train Epoch 53: 160/167 Loss: 19.481649
2023-05-18 15:46: **********Train Epoch 53: averaged Loss: 18.795610, tf_ratio: 1.000000
2023-05-18 15:46: **********Val Epoch 53: average Loss: 18.983813
2023-05-18 15:46: Train Epoch 54: 0/167 Loss: 17.402643
2023-05-18 15:46: Train Epoch 54: 20/167 Loss: 18.793158
2023-05-18 15:46: Train Epoch 54: 40/167 Loss: 17.276762
2023-05-18 15:46: Train Epoch 54: 60/167 Loss: 19.256983
2023-05-18 15:46: Train Epoch 54: 80/167 Loss: 19.574017
2023-05-18 15:46: Train Epoch 54: 100/167 Loss: 18.996271
2023-05-18 15:46: Train Epoch 54: 120/167 Loss: 18.603491
2023-05-18 15:46: Train Epoch 54: 140/167 Loss: 17.366381
2023-05-18 15:46: Train Epoch 54: 160/167 Loss: 18.712421
2023-05-18 15:46: **********Train Epoch 54: averaged Loss: 18.861588, tf_ratio: 1.000000
2023-05-18 15:46: **********Val Epoch 54: average Loss: 19.279159
2023-05-18 15:46: Train Epoch 55: 0/167 Loss: 19.735943
2023-05-18 15:46: Train Epoch 55: 20/167 Loss: 18.844532
2023-05-18 15:46: Train Epoch 55: 40/167 Loss: 19.881933
2023-05-18 15:46: Train Epoch 55: 60/167 Loss: 19.044729
2023-05-18 15:46: Train Epoch 55: 80/167 Loss: 17.968176
2023-05-18 15:47: Train Epoch 55: 100/167 Loss: 19.734947
2023-05-18 15:47: Train Epoch 55: 120/167 Loss: 19.797987
2023-05-18 15:47: Train Epoch 55: 140/167 Loss: 20.027067
2023-05-18 15:47: Train Epoch 55: 160/167 Loss: 20.181910
2023-05-18 15:47: **********Train Epoch 55: averaged Loss: 18.837646, tf_ratio: 1.000000
2023-05-18 15:47: **********Val Epoch 55: average Loss: 20.257862
2023-05-18 15:47: Train Epoch 56: 0/167 Loss: 19.663279
2023-05-18 15:47: Train Epoch 56: 20/167 Loss: 19.395815
2023-05-18 15:47: Train Epoch 56: 40/167 Loss: 19.570675
2023-05-18 15:47: Train Epoch 56: 60/167 Loss: 18.078695
2023-05-18 15:47: Train Epoch 56: 80/167 Loss: 17.556728
2023-05-18 15:47: Train Epoch 56: 100/167 Loss: 19.099768
2023-05-18 15:47: Train Epoch 56: 120/167 Loss: 19.361465
2023-05-18 15:47: Train Epoch 56: 140/167 Loss: 18.722355
2023-05-18 15:47: Train Epoch 56: 160/167 Loss: 18.801210
2023-05-18 15:47: **********Train Epoch 56: averaged Loss: 18.960430, tf_ratio: 1.000000
2023-05-18 15:47: **********Val Epoch 56: average Loss: 19.263716
2023-05-18 15:47: Train Epoch 57: 0/167 Loss: 18.147316
2023-05-18 15:47: Train Epoch 57: 20/167 Loss: 18.741438
2023-05-18 15:47: Train Epoch 57: 40/167 Loss: 17.724852
2023-05-18 15:47: Train Epoch 57: 60/167 Loss: 16.998648
2023-05-18 15:47: Train Epoch 57: 80/167 Loss: 18.636995
2023-05-18 15:47: Train Epoch 57: 100/167 Loss: 18.513170
2023-05-18 15:47: Train Epoch 57: 120/167 Loss: 19.969261
2023-05-18 15:47: Train Epoch 57: 140/167 Loss: 18.254057
2023-05-18 15:47: Train Epoch 57: 160/167 Loss: 18.156513
2023-05-18 15:47: **********Train Epoch 57: averaged Loss: 18.624032, tf_ratio: 1.000000
2023-05-18 15:47: **********Val Epoch 57: average Loss: 19.058259
2023-05-18 15:47: Train Epoch 58: 0/167 Loss: 17.217642
2023-05-18 15:47: Train Epoch 58: 20/167 Loss: 19.454874
2023-05-18 15:47: Train Epoch 58: 40/167 Loss: 17.720188
2023-05-18 15:47: Train Epoch 58: 60/167 Loss: 19.511892
2023-05-18 15:47: Train Epoch 58: 80/167 Loss: 18.457399
2023-05-18 15:47: Train Epoch 58: 100/167 Loss: 18.302719
2023-05-18 15:47: Train Epoch 58: 120/167 Loss: 17.444305
2023-05-18 15:47: Train Epoch 58: 140/167 Loss: 18.984715
2023-05-18 15:48: Train Epoch 58: 160/167 Loss: 18.209234
2023-05-18 15:48: **********Train Epoch 58: averaged Loss: 18.639106, tf_ratio: 1.000000
2023-05-18 15:48: **********Val Epoch 58: average Loss: 18.898549
2023-05-18 15:48: ******Current best model saved:model_para/PEMSD8/epoch_58.pth!
2023-05-18 15:48: Train Epoch 59: 0/167 Loss: 17.250565
2023-05-18 15:48: Train Epoch 59: 20/167 Loss: 18.943796
2023-05-18 15:48: Train Epoch 59: 40/167 Loss: 18.930233
2023-05-18 15:48: Train Epoch 59: 60/167 Loss: 19.162590
2023-05-18 15:48: Train Epoch 59: 80/167 Loss: 18.836550
2023-05-18 15:48: Train Epoch 59: 100/167 Loss: 19.569561
2023-05-18 15:48: Train Epoch 59: 120/167 Loss: 20.572502
2023-05-18 15:48: Train Epoch 59: 140/167 Loss: 18.989124
2023-05-18 15:48: Train Epoch 59: 160/167 Loss: 16.286913
2023-05-18 15:48: **********Train Epoch 59: averaged Loss: 18.623825, tf_ratio: 1.000000
2023-05-18 15:48: **********Val Epoch 59: average Loss: 18.788809
2023-05-18 15:48: ******Current best model saved:model_para/PEMSD8/epoch_59.pth!
2023-05-18 15:48: Train Epoch 60: 0/167 Loss: 19.119629
2023-05-18 15:48: Train Epoch 60: 20/167 Loss: 18.625767
2023-05-18 15:48: Train Epoch 60: 40/167 Loss: 19.648201
2023-05-18 15:48: Train Epoch 60: 60/167 Loss: 18.406490
2023-05-18 15:48: Train Epoch 60: 80/167 Loss: 18.767035
2023-05-18 15:48: Train Epoch 60: 100/167 Loss: 19.505714
2023-05-18 15:48: Train Epoch 60: 120/167 Loss: 18.037897
2023-05-18 15:48: Train Epoch 60: 140/167 Loss: 17.430658
2023-05-18 15:48: Train Epoch 60: 160/167 Loss: 19.422152
2023-05-18 15:48: **********Train Epoch 60: averaged Loss: 18.687015, tf_ratio: 1.000000
2023-05-18 15:48: **********Val Epoch 60: average Loss: 19.375088
2023-05-18 15:48: Train Epoch 61: 0/167 Loss: 20.241758
2023-05-18 15:48: Train Epoch 61: 20/167 Loss: 18.304333
2023-05-18 15:48: Train Epoch 61: 40/167 Loss: 19.731060
2023-05-18 15:48: Train Epoch 61: 60/167 Loss: 18.998333
2023-05-18 15:48: Train Epoch 61: 80/167 Loss: 18.961056
2023-05-18 15:48: Train Epoch 61: 100/167 Loss: 18.851463
2023-05-18 15:48: Train Epoch 61: 120/167 Loss: 17.898445
2023-05-18 15:48: Train Epoch 61: 140/167 Loss: 18.482191
2023-05-18 15:48: Train Epoch 61: 160/167 Loss: 19.278988
2023-05-18 15:48: **********Train Epoch 61: averaged Loss: 18.687862, tf_ratio: 1.000000
2023-05-18 15:48: **********Val Epoch 61: average Loss: 18.838152
2023-05-18 15:48: Train Epoch 62: 0/167 Loss: 19.284834
2023-05-18 15:48: Train Epoch 62: 20/167 Loss: 18.923508
2023-05-18 15:48: Train Epoch 62: 40/167 Loss: 16.990417
2023-05-18 15:49: Train Epoch 62: 60/167 Loss: 18.363623
2023-05-18 15:49: Train Epoch 62: 80/167 Loss: 19.542858
2023-05-18 15:49: Train Epoch 62: 100/167 Loss: 18.659521
2023-05-18 15:49: Train Epoch 62: 120/167 Loss: 19.220165
2023-05-18 15:49: Train Epoch 62: 140/167 Loss: 17.542587
2023-05-18 15:49: Train Epoch 62: 160/167 Loss: 18.664967
2023-05-18 15:49: **********Train Epoch 62: averaged Loss: 18.593241, tf_ratio: 1.000000
2023-05-18 15:49: **********Val Epoch 62: average Loss: 18.777388
2023-05-18 15:49: ******Current best model saved:model_para/PEMSD8/epoch_62.pth!
2023-05-18 15:49: Train Epoch 63: 0/167 Loss: 18.044765
2023-05-18 15:49: Train Epoch 63: 20/167 Loss: 17.952280
2023-05-18 15:49: Train Epoch 63: 40/167 Loss: 17.870831
2023-05-18 15:49: Train Epoch 63: 60/167 Loss: 17.515787
2023-05-18 15:49: Train Epoch 63: 80/167 Loss: 19.121983
2023-05-18 15:49: Train Epoch 63: 100/167 Loss: 18.593584
2023-05-18 15:49: Train Epoch 63: 120/167 Loss: 18.219938
2023-05-18 15:49: Train Epoch 63: 140/167 Loss: 19.047880
2023-05-18 15:49: Train Epoch 63: 160/167 Loss: 19.444666
2023-05-18 15:49: **********Train Epoch 63: averaged Loss: 18.488134, tf_ratio: 1.000000
2023-05-18 15:49: **********Val Epoch 63: average Loss: 18.824173
2023-05-18 15:49: Train Epoch 64: 0/167 Loss: 18.939976
2023-05-18 15:49: Train Epoch 64: 20/167 Loss: 18.718725
2023-05-18 15:49: Train Epoch 64: 40/167 Loss: 17.481653
2023-05-18 15:49: Train Epoch 64: 60/167 Loss: 18.188013
2023-05-18 15:49: Train Epoch 64: 80/167 Loss: 19.454054
2023-05-18 15:49: Train Epoch 64: 100/167 Loss: 17.451035
2023-05-18 15:49: Train Epoch 64: 120/167 Loss: 18.146639
2023-05-18 15:49: Train Epoch 64: 140/167 Loss: 19.254425
2023-05-18 15:49: Train Epoch 64: 160/167 Loss: 19.537460
2023-05-18 15:49: **********Train Epoch 64: averaged Loss: 18.614794, tf_ratio: 1.000000
2023-05-18 15:49: **********Val Epoch 64: average Loss: 18.914534
2023-05-18 15:49: Train Epoch 65: 0/167 Loss: 17.679884
2023-05-18 15:49: Train Epoch 65: 20/167 Loss: 17.405872
2023-05-18 15:49: Train Epoch 65: 40/167 Loss: 17.921217
2023-05-18 15:49: Train Epoch 65: 60/167 Loss: 17.191051
2023-05-18 15:49: Train Epoch 65: 80/167 Loss: 18.134815
2023-05-18 15:49: Train Epoch 65: 100/167 Loss: 19.311243
2023-05-18 15:50: Train Epoch 65: 120/167 Loss: 17.813400
2023-05-18 15:50: Train Epoch 65: 140/167 Loss: 19.922987
2023-05-18 15:50: Train Epoch 65: 160/167 Loss: 17.894098
2023-05-18 15:50: **********Train Epoch 65: averaged Loss: 18.626990, tf_ratio: 1.000000
2023-05-18 15:50: **********Val Epoch 65: average Loss: 18.716879
2023-05-18 15:50: ******Current best model saved:model_para/PEMSD8/epoch_65.pth!
2023-05-18 15:50: Train Epoch 66: 0/167 Loss: 19.277164
2023-05-18 15:50: Train Epoch 66: 20/167 Loss: 18.755533
2023-05-18 15:50: Train Epoch 66: 40/167 Loss: 19.149033
2023-05-18 15:50: Train Epoch 66: 60/167 Loss: 17.789190
2023-05-18 15:50: Train Epoch 66: 80/167 Loss: 19.099342
2023-05-18 15:50: Train Epoch 66: 100/167 Loss: 18.460230
2023-05-18 15:50: Train Epoch 66: 120/167 Loss: 17.756233
2023-05-18 15:50: Train Epoch 66: 140/167 Loss: 18.247095
2023-05-18 15:50: Train Epoch 66: 160/167 Loss: 19.115351
2023-05-18 15:50: **********Train Epoch 66: averaged Loss: 18.453156, tf_ratio: 1.000000
2023-05-18 15:50: **********Val Epoch 66: average Loss: 18.849932
2023-05-18 15:50: Train Epoch 67: 0/167 Loss: 19.119999
2023-05-18 15:50: Train Epoch 67: 20/167 Loss: 18.843620
2023-05-18 15:50: Train Epoch 67: 40/167 Loss: 18.792322
2023-05-18 15:50: Train Epoch 67: 60/167 Loss: 19.582928
2023-05-18 15:50: Train Epoch 67: 80/167 Loss: 18.026917
2023-05-18 15:50: Train Epoch 67: 100/167 Loss: 19.329590
2023-05-18 15:50: Train Epoch 67: 120/167 Loss: 18.824051
2023-05-18 15:50: Train Epoch 67: 140/167 Loss: 18.812483
2023-05-18 15:50: Train Epoch 67: 160/167 Loss: 18.160156
2023-05-18 15:50: **********Train Epoch 67: averaged Loss: 18.473292, tf_ratio: 1.000000
2023-05-18 15:50: **********Val Epoch 67: average Loss: 18.980332
2023-05-18 15:50: Train Epoch 68: 0/167 Loss: 18.123255
2023-05-18 15:50: Train Epoch 68: 20/167 Loss: 17.928467
2023-05-18 15:50: Train Epoch 68: 40/167 Loss: 17.568052
2023-05-18 15:50: Train Epoch 68: 60/167 Loss: 20.009357
2023-05-18 15:50: Train Epoch 68: 80/167 Loss: 18.364433
2023-05-18 15:50: Train Epoch 68: 100/167 Loss: 17.847904
2023-05-18 15:50: Train Epoch 68: 120/167 Loss: 18.847826
2023-05-18 15:50: Train Epoch 68: 140/167 Loss: 18.531204
2023-05-18 15:50: Train Epoch 68: 160/167 Loss: 18.707125
2023-05-18 15:50: **********Train Epoch 68: averaged Loss: 18.570340, tf_ratio: 1.000000
2023-05-18 15:50: **********Val Epoch 68: average Loss: 19.320028
2023-05-18 15:50: Train Epoch 69: 0/167 Loss: 17.925545
2023-05-18 15:51: Train Epoch 69: 20/167 Loss: 18.958265
2023-05-18 15:51: Train Epoch 69: 40/167 Loss: 19.066687
2023-05-18 15:51: Train Epoch 69: 60/167 Loss: 18.713509
2023-05-18 15:51: Train Epoch 69: 80/167 Loss: 17.972052
2023-05-18 15:51: Train Epoch 69: 100/167 Loss: 19.321230
2023-05-18 15:51: Train Epoch 69: 120/167 Loss: 19.184820
2023-05-18 15:51: Train Epoch 69: 140/167 Loss: 18.796312
2023-05-18 15:51: Train Epoch 69: 160/167 Loss: 19.577450
2023-05-18 15:51: **********Train Epoch 69: averaged Loss: 18.495158, tf_ratio: 1.000000
2023-05-18 15:51: **********Val Epoch 69: average Loss: 18.589674
2023-05-18 15:51: ******Current best model saved:model_para/PEMSD8/epoch_69.pth!
2023-05-18 15:51: Train Epoch 70: 0/167 Loss: 19.576275
2023-05-18 15:51: Train Epoch 70: 20/167 Loss: 17.259571
2023-05-18 15:51: Train Epoch 70: 40/167 Loss: 18.516577
2023-05-18 15:51: Train Epoch 70: 60/167 Loss: 18.895597
2023-05-18 15:51: Train Epoch 70: 80/167 Loss: 19.270044
2023-05-18 15:51: Train Epoch 70: 100/167 Loss: 18.820383
2023-05-18 15:51: Train Epoch 70: 120/167 Loss: 18.589041
2023-05-18 15:51: Train Epoch 70: 140/167 Loss: 19.539068
2023-05-18 15:51: Train Epoch 70: 160/167 Loss: 18.156809
2023-05-18 15:51: **********Train Epoch 70: averaged Loss: 18.450663, tf_ratio: 1.000000
2023-05-18 15:51: **********Val Epoch 70: average Loss: 18.966083
2023-05-18 15:51: Train Epoch 71: 0/167 Loss: 20.423048
2023-05-18 15:51: Train Epoch 71: 20/167 Loss: 18.458851
2023-05-18 15:51: Train Epoch 71: 40/167 Loss: 18.509996
2023-05-18 15:51: Train Epoch 71: 60/167 Loss: 17.791767
2023-05-18 15:51: Train Epoch 71: 80/167 Loss: 19.531057
2023-05-18 15:51: Train Epoch 71: 100/167 Loss: 18.800041
2023-05-18 15:51: Train Epoch 71: 120/167 Loss: 18.330074
2023-05-18 15:51: Train Epoch 71: 140/167 Loss: 20.004112
2023-05-18 15:51: Train Epoch 71: 160/167 Loss: 18.276196
2023-05-18 15:51: **********Train Epoch 71: averaged Loss: 18.562968, tf_ratio: 1.000000
2023-05-18 15:51: **********Val Epoch 71: average Loss: 18.966074
2023-05-18 15:51: Train Epoch 72: 0/167 Loss: 20.015432
2023-05-18 15:51: Train Epoch 72: 20/167 Loss: 18.428616
2023-05-18 15:51: Train Epoch 72: 40/167 Loss: 18.376493
2023-05-18 15:51: Train Epoch 72: 60/167 Loss: 19.358557
2023-05-18 15:52: Train Epoch 72: 80/167 Loss: 17.536961
2023-05-18 15:52: Train Epoch 72: 100/167 Loss: 17.647833
2023-05-18 15:52: Train Epoch 72: 120/167 Loss: 18.343479
2023-05-18 15:52: Train Epoch 72: 140/167 Loss: 18.881292
2023-05-18 15:52: Train Epoch 72: 160/167 Loss: 18.804605
2023-05-18 15:52: **********Train Epoch 72: averaged Loss: 18.429963, tf_ratio: 1.000000
2023-05-18 15:52: **********Val Epoch 72: average Loss: 18.868755
2023-05-18 15:52: Train Epoch 73: 0/167 Loss: 17.074602
2023-05-18 15:52: Train Epoch 73: 20/167 Loss: 18.792774
2023-05-18 15:52: Train Epoch 73: 40/167 Loss: 19.080303
2023-05-18 15:52: Train Epoch 73: 60/167 Loss: 17.982550
2023-05-18 15:52: Train Epoch 73: 80/167 Loss: 17.081148
2023-05-18 15:52: Train Epoch 73: 100/167 Loss: 19.468046
2023-05-18 15:52: Train Epoch 73: 120/167 Loss: 17.347557
2023-05-18 15:52: Train Epoch 73: 140/167 Loss: 19.368738
2023-05-18 15:52: Train Epoch 73: 160/167 Loss: 18.061411
2023-05-18 15:52: **********Train Epoch 73: averaged Loss: 18.406183, tf_ratio: 1.000000
2023-05-18 15:52: **********Val Epoch 73: average Loss: 18.809748
2023-05-18 15:52: Train Epoch 74: 0/167 Loss: 18.141487
2023-05-18 15:52: Train Epoch 74: 20/167 Loss: 19.053246
2023-05-18 15:52: Train Epoch 74: 40/167 Loss: 19.461332
2023-05-18 15:52: Train Epoch 74: 60/167 Loss: 19.084034
2023-05-18 15:52: Train Epoch 74: 80/167 Loss: 17.931318
2023-05-18 15:52: Train Epoch 74: 100/167 Loss: 17.673862
2023-05-18 15:52: Train Epoch 74: 120/167 Loss: 19.117004
2023-05-18 15:52: Train Epoch 74: 140/167 Loss: 18.293655
2023-05-18 15:52: Train Epoch 74: 160/167 Loss: 18.886276
2023-05-18 15:52: **********Train Epoch 74: averaged Loss: 18.318300, tf_ratio: 1.000000
2023-05-18 15:52: **********Val Epoch 74: average Loss: 18.602390
2023-05-18 15:52: Train Epoch 75: 0/167 Loss: 18.176004
2023-05-18 15:52: Train Epoch 75: 20/167 Loss: 18.669338
2023-05-18 15:52: Train Epoch 75: 40/167 Loss: 19.075981
2023-05-18 15:52: Train Epoch 75: 60/167 Loss: 17.633663
2023-05-18 15:52: Train Epoch 75: 80/167 Loss: 17.531488
2023-05-18 15:52: Train Epoch 75: 100/167 Loss: 18.287338
2023-05-18 15:53: Train Epoch 75: 120/167 Loss: 19.576944
2023-05-18 15:53: Train Epoch 75: 140/167 Loss: 18.793203
2023-05-18 15:53: Train Epoch 75: 160/167 Loss: 18.659971
2023-05-18 15:53: **********Train Epoch 75: averaged Loss: 18.520607, tf_ratio: 1.000000
2023-05-18 15:53: **********Val Epoch 75: average Loss: 18.705519
2023-05-18 15:53: Train Epoch 76: 0/167 Loss: 17.739796
2023-05-18 15:53: Train Epoch 76: 20/167 Loss: 18.960264
2023-05-18 15:53: Train Epoch 76: 40/167 Loss: 18.276028
2023-05-18 15:53: Train Epoch 76: 60/167 Loss: 19.879038
2023-05-18 15:53: Train Epoch 76: 80/167 Loss: 19.092596
2023-05-18 15:53: Train Epoch 76: 100/167 Loss: 19.958691
2023-05-18 15:53: Train Epoch 76: 120/167 Loss: 19.011456
2023-05-18 15:53: Train Epoch 76: 140/167 Loss: 17.933935
2023-05-18 15:53: Train Epoch 76: 160/167 Loss: 18.150709
2023-05-18 15:53: **********Train Epoch 76: averaged Loss: 18.369958, tf_ratio: 1.000000
2023-05-18 15:53: **********Val Epoch 76: average Loss: 18.762620
2023-05-18 15:53: Train Epoch 77: 0/167 Loss: 18.719995
2023-05-18 15:53: Train Epoch 77: 20/167 Loss: 18.281321
2023-05-18 15:53: Train Epoch 77: 40/167 Loss: 18.573011
2023-05-18 15:53: Train Epoch 77: 60/167 Loss: 17.653433
2023-05-18 15:53: Train Epoch 77: 80/167 Loss: 17.935329
2023-05-18 15:53: Train Epoch 77: 100/167 Loss: 19.762735
2023-05-18 15:53: Train Epoch 77: 120/167 Loss: 18.269199
2023-05-18 15:53: Train Epoch 77: 140/167 Loss: 19.721970
2023-05-18 15:53: Train Epoch 77: 160/167 Loss: 18.556587
2023-05-18 15:53: **********Train Epoch 77: averaged Loss: 18.359201, tf_ratio: 1.000000
2023-05-18 15:53: **********Val Epoch 77: average Loss: 19.028783
2023-05-18 15:53: Train Epoch 78: 0/167 Loss: 18.110916
2023-05-18 15:53: Train Epoch 78: 20/167 Loss: 19.821081
2023-05-18 15:53: Train Epoch 78: 40/167 Loss: 18.219797
2023-05-18 15:53: Train Epoch 78: 60/167 Loss: 16.649397
2023-05-18 15:53: Train Epoch 78: 80/167 Loss: 18.229982
2023-05-18 15:53: Train Epoch 78: 100/167 Loss: 20.124247
2023-05-18 15:53: Train Epoch 78: 120/167 Loss: 19.020090
2023-05-18 15:54: Train Epoch 78: 140/167 Loss: 19.290211
2023-05-18 15:54: Train Epoch 78: 160/167 Loss: 18.003502
2023-05-18 15:54: **********Train Epoch 78: averaged Loss: 18.362650, tf_ratio: 1.000000
2023-05-18 15:54: **********Val Epoch 78: average Loss: 18.691209
2023-05-18 15:54: Train Epoch 79: 0/167 Loss: 18.208485
2023-05-18 15:54: Train Epoch 79: 20/167 Loss: 18.457010
2023-05-18 15:54: Train Epoch 79: 40/167 Loss: 18.796194
2023-05-18 15:54: Train Epoch 79: 60/167 Loss: 17.120678
2023-05-18 15:54: Train Epoch 79: 80/167 Loss: 18.532887
2023-05-18 15:54: Train Epoch 79: 100/167 Loss: 16.562483
2023-05-18 15:54: Train Epoch 79: 120/167 Loss: 18.793503
2023-05-18 15:54: Train Epoch 79: 140/167 Loss: 19.524603
2023-05-18 15:54: Train Epoch 79: 160/167 Loss: 19.369045
2023-05-18 15:54: **********Train Epoch 79: averaged Loss: 18.518982, tf_ratio: 1.000000
2023-05-18 15:54: **********Val Epoch 79: average Loss: 19.026182
2023-05-18 15:54: Train Epoch 80: 0/167 Loss: 19.713957
2023-05-18 15:54: Train Epoch 80: 20/167 Loss: 18.185497
2023-05-18 15:54: Train Epoch 80: 40/167 Loss: 18.216682
2023-05-18 15:54: Train Epoch 80: 60/167 Loss: 19.186518
2023-05-18 15:54: Train Epoch 80: 80/167 Loss: 17.567581
2023-05-18 15:54: Train Epoch 80: 100/167 Loss: 17.151279
2023-05-18 15:54: Train Epoch 80: 120/167 Loss: 17.317936
2023-05-18 15:54: Train Epoch 80: 140/167 Loss: 18.782969
2023-05-18 15:54: Train Epoch 80: 160/167 Loss: 16.981163
2023-05-18 15:54: **********Train Epoch 80: averaged Loss: 18.318027, tf_ratio: 1.000000
2023-05-18 15:54: **********Val Epoch 80: average Loss: 18.925900
2023-05-18 15:54: Train Epoch 81: 0/167 Loss: 16.946911
2023-05-18 15:54: Train Epoch 81: 20/167 Loss: 19.804342
2023-05-18 15:54: Train Epoch 81: 40/167 Loss: 19.169058
2023-05-18 15:54: Train Epoch 81: 60/167 Loss: 18.400408
2023-05-18 15:54: Train Epoch 81: 80/167 Loss: 20.742107
2023-05-18 15:54: Train Epoch 81: 100/167 Loss: 18.805019
2023-05-18 15:54: Train Epoch 81: 120/167 Loss: 17.114950
2023-05-18 15:54: Train Epoch 81: 140/167 Loss: 19.328409
2023-05-18 15:55: Train Epoch 81: 160/167 Loss: 18.569042
2023-05-18 15:55: **********Train Epoch 81: averaged Loss: 18.401464, tf_ratio: 1.000000
2023-05-18 15:55: **********Val Epoch 81: average Loss: 18.657642
2023-05-18 15:55: Train Epoch 82: 0/167 Loss: 19.076704
2023-05-18 15:55: Train Epoch 82: 20/167 Loss: 15.785621
2023-05-18 15:55: Train Epoch 82: 40/167 Loss: 18.887976
2023-05-18 15:55: Train Epoch 82: 60/167 Loss: 19.442671
2023-05-18 15:55: Train Epoch 82: 80/167 Loss: 17.937746
2023-05-18 15:55: Train Epoch 82: 100/167 Loss: 17.936743
2023-05-18 15:55: Train Epoch 82: 120/167 Loss: 18.984808
2023-05-18 15:55: Train Epoch 82: 140/167 Loss: 17.476116
2023-05-18 15:55: Train Epoch 82: 160/167 Loss: 17.690704
2023-05-18 15:55: **********Train Epoch 82: averaged Loss: 18.312146, tf_ratio: 1.000000
2023-05-18 15:55: **********Val Epoch 82: average Loss: 18.593518
2023-05-18 15:55: Train Epoch 83: 0/167 Loss: 19.478502
2023-05-18 15:55: Train Epoch 83: 20/167 Loss: 20.152094
2023-05-18 15:55: Train Epoch 83: 40/167 Loss: 18.677042
2023-05-18 15:55: Train Epoch 83: 60/167 Loss: 17.639507
2023-05-18 15:55: Train Epoch 83: 80/167 Loss: 17.551594
2023-05-18 15:55: Train Epoch 83: 100/167 Loss: 18.098246
2023-05-18 15:55: Train Epoch 83: 120/167 Loss: 17.904087
2023-05-18 15:55: Train Epoch 83: 140/167 Loss: 18.557550
2023-05-18 15:55: Train Epoch 83: 160/167 Loss: 20.145290
2023-05-18 15:55: **********Train Epoch 83: averaged Loss: 18.340273, tf_ratio: 1.000000
2023-05-18 15:55: **********Val Epoch 83: average Loss: 18.644961
2023-05-18 15:55: Train Epoch 84: 0/167 Loss: 19.128202
2023-05-18 15:55: Train Epoch 84: 20/167 Loss: 17.914433
2023-05-18 15:55: Train Epoch 84: 40/167 Loss: 17.875242
2023-05-18 15:55: Train Epoch 84: 60/167 Loss: 18.921566
2023-05-18 15:55: Train Epoch 84: 80/167 Loss: 17.980570
2023-05-18 15:55: Train Epoch 84: 100/167 Loss: 19.834766
2023-05-18 15:55: Train Epoch 84: 120/167 Loss: 18.336988
2023-05-18 15:55: Train Epoch 84: 140/167 Loss: 17.621897
2023-05-18 15:55: Train Epoch 84: 160/167 Loss: 17.150354
2023-05-18 15:55: **********Train Epoch 84: averaged Loss: 18.230511, tf_ratio: 1.000000
2023-05-18 15:56: **********Val Epoch 84: average Loss: 18.821507
2023-05-18 15:56: Train Epoch 85: 0/167 Loss: 20.573278
2023-05-18 15:56: Train Epoch 85: 20/167 Loss: 17.821785
2023-05-18 15:56: Train Epoch 85: 40/167 Loss: 18.605490
2023-05-18 15:56: Train Epoch 85: 60/167 Loss: 18.780373
2023-05-18 15:56: Train Epoch 85: 80/167 Loss: 18.003429
2023-05-18 15:56: Train Epoch 85: 100/167 Loss: 17.748125
2023-05-18 15:56: Train Epoch 85: 120/167 Loss: 16.685312
2023-05-18 15:56: Train Epoch 85: 140/167 Loss: 18.168539
2023-05-18 15:56: Train Epoch 85: 160/167 Loss: 16.688524
2023-05-18 15:56: **********Train Epoch 85: averaged Loss: 18.304833, tf_ratio: 1.000000
2023-05-18 15:56: **********Val Epoch 85: average Loss: 18.712360
2023-05-18 15:56: Train Epoch 86: 0/167 Loss: 18.337503
2023-05-18 15:56: Train Epoch 86: 20/167 Loss: 18.097179
2023-05-18 15:56: Train Epoch 86: 40/167 Loss: 17.274130
2023-05-18 15:56: Train Epoch 86: 60/167 Loss: 17.743193
2023-05-18 15:56: Train Epoch 86: 80/167 Loss: 18.414268
2023-05-18 15:56: Train Epoch 86: 100/167 Loss: 18.135939
2023-05-18 15:56: Train Epoch 86: 120/167 Loss: 17.840370
2023-05-18 15:56: Train Epoch 86: 140/167 Loss: 18.791645
2023-05-18 15:56: Train Epoch 86: 160/167 Loss: 18.511759
2023-05-18 15:56: **********Train Epoch 86: averaged Loss: 18.293535, tf_ratio: 1.000000
2023-05-18 15:56: **********Val Epoch 86: average Loss: 18.784391
2023-05-18 15:56: Train Epoch 87: 0/167 Loss: 18.498653
2023-05-18 15:56: Train Epoch 87: 20/167 Loss: 19.803318
2023-05-18 15:56: Train Epoch 87: 40/167 Loss: 17.822245
2023-05-18 15:56: Train Epoch 87: 60/167 Loss: 18.597363
2023-05-18 15:56: Train Epoch 87: 80/167 Loss: 19.344183
2023-05-18 15:56: Train Epoch 87: 100/167 Loss: 17.347166
2023-05-18 15:56: Train Epoch 87: 120/167 Loss: 18.109596
2023-05-18 15:56: Train Epoch 87: 140/167 Loss: 17.156803
2023-05-18 15:56: Train Epoch 87: 160/167 Loss: 18.874201
2023-05-18 15:56: **********Train Epoch 87: averaged Loss: 18.242789, tf_ratio: 1.000000
2023-05-18 15:56: **********Val Epoch 87: average Loss: 18.430956
2023-05-18 15:56: ******Current best model saved:model_para/PEMSD8/epoch_87.pth!
2023-05-18 15:56: Train Epoch 88: 0/167 Loss: 18.339918
2023-05-18 15:57: Train Epoch 88: 20/167 Loss: 17.331741
2023-05-18 15:57: Train Epoch 88: 40/167 Loss: 18.553566
2023-05-18 15:57: Train Epoch 88: 60/167 Loss: 18.608473
2023-05-18 15:57: Train Epoch 88: 80/167 Loss: 18.513960
2023-05-18 15:57: Train Epoch 88: 100/167 Loss: 19.362631
2023-05-18 15:57: Train Epoch 88: 120/167 Loss: 18.371483
2023-05-18 15:57: Train Epoch 88: 140/167 Loss: 17.592890
2023-05-18 15:57: Train Epoch 88: 160/167 Loss: 17.560017
2023-05-18 15:57: **********Train Epoch 88: averaged Loss: 18.241558, tf_ratio: 1.000000
2023-05-18 15:57: **********Val Epoch 88: average Loss: 18.863585
2023-05-18 15:57: Train Epoch 89: 0/167 Loss: 19.698078
2023-05-18 15:57: Train Epoch 89: 20/167 Loss: 17.240620
2023-05-18 15:57: Train Epoch 89: 40/167 Loss: 18.455276
2023-05-18 15:57: Train Epoch 89: 60/167 Loss: 18.769377
2023-05-18 15:57: Train Epoch 89: 80/167 Loss: 17.733423
2023-05-18 15:57: Train Epoch 89: 100/167 Loss: 17.395983
2023-05-18 15:57: Train Epoch 89: 120/167 Loss: 18.977205
2023-05-18 15:57: Train Epoch 89: 140/167 Loss: 18.834650
2023-05-18 15:57: Train Epoch 89: 160/167 Loss: 18.803539
2023-05-18 15:57: **********Train Epoch 89: averaged Loss: 18.397403, tf_ratio: 1.000000
2023-05-18 15:57: **********Val Epoch 89: average Loss: 18.898176
2023-05-18 15:57: Train Epoch 90: 0/167 Loss: 19.715378
2023-05-18 15:57: Train Epoch 90: 20/167 Loss: 18.177813
2023-05-18 15:57: Train Epoch 90: 40/167 Loss: 18.006180
2023-05-18 15:57: Train Epoch 90: 60/167 Loss: 17.502005
2023-05-18 15:57: Train Epoch 90: 80/167 Loss: 18.007481
2023-05-18 15:57: Train Epoch 90: 100/167 Loss: 18.638187
2023-05-18 15:57: Train Epoch 90: 120/167 Loss: 16.452284
2023-05-18 15:57: Train Epoch 90: 140/167 Loss: 18.958185
2023-05-18 15:57: Train Epoch 90: 160/167 Loss: 17.901682
2023-05-18 15:57: **********Train Epoch 90: averaged Loss: 18.301173, tf_ratio: 1.000000
2023-05-18 15:57: **********Val Epoch 90: average Loss: 18.777328
2023-05-18 15:57: Train Epoch 91: 0/167 Loss: 18.840109
2023-05-18 15:57: Train Epoch 91: 20/167 Loss: 17.077805
2023-05-18 15:58: Train Epoch 91: 40/167 Loss: 18.223783
2023-05-18 15:58: Train Epoch 91: 60/167 Loss: 18.696171
2023-05-18 15:58: Train Epoch 91: 80/167 Loss: 18.264620
2023-05-18 15:58: Train Epoch 91: 100/167 Loss: 17.225395
2023-05-18 15:58: Train Epoch 91: 120/167 Loss: 19.058981
2023-05-18 15:58: Train Epoch 91: 140/167 Loss: 18.050694
2023-05-18 15:58: Train Epoch 91: 160/167 Loss: 18.395086
2023-05-18 15:58: **********Train Epoch 91: averaged Loss: 18.257866, tf_ratio: 1.000000
2023-05-18 15:58: **********Val Epoch 91: average Loss: 18.482431
2023-05-18 15:58: Train Epoch 92: 0/167 Loss: 18.324013
2023-05-18 15:58: Train Epoch 92: 20/167 Loss: 17.485626
2023-05-18 15:58: Train Epoch 92: 40/167 Loss: 17.786499
2023-05-18 15:58: Train Epoch 92: 60/167 Loss: 18.592230
2023-05-18 15:58: Train Epoch 92: 80/167 Loss: 16.895391
2023-05-18 15:58: Train Epoch 92: 100/167 Loss: 17.765511
2023-05-18 15:58: Train Epoch 92: 120/167 Loss: 18.473841
2023-05-18 15:58: Train Epoch 92: 140/167 Loss: 18.950966
2023-05-18 15:58: Train Epoch 92: 160/167 Loss: 16.849646
2023-05-18 15:58: **********Train Epoch 92: averaged Loss: 18.162935, tf_ratio: 1.000000
2023-05-18 15:58: **********Val Epoch 92: average Loss: 18.583721
2023-05-18 15:58: Train Epoch 93: 0/167 Loss: 17.124201
2023-05-18 15:58: Train Epoch 93: 20/167 Loss: 18.270681
2023-05-18 15:58: Train Epoch 93: 40/167 Loss: 19.162025
2023-05-18 15:58: Train Epoch 93: 60/167 Loss: 19.813635
2023-05-18 15:58: Train Epoch 93: 80/167 Loss: 18.694717
2023-05-18 15:58: Train Epoch 93: 100/167 Loss: 18.701494
2023-05-18 15:58: Train Epoch 93: 120/167 Loss: 17.698128
2023-05-18 15:58: Train Epoch 93: 140/167 Loss: 17.980749
2023-05-18 15:58: Train Epoch 93: 160/167 Loss: 17.453939
2023-05-18 15:58: **********Train Epoch 93: averaged Loss: 18.293393, tf_ratio: 1.000000
2023-05-18 15:58: **********Val Epoch 93: average Loss: 18.450196
2023-05-18 15:58: Train Epoch 94: 0/167 Loss: 17.198477
2023-05-18 15:58: Train Epoch 94: 20/167 Loss: 18.007044
2023-05-18 15:58: Train Epoch 94: 40/167 Loss: 18.586100
2023-05-18 15:59: Train Epoch 94: 60/167 Loss: 17.875216
2023-05-18 15:59: Train Epoch 94: 80/167 Loss: 20.129570
2023-05-18 15:59: Train Epoch 94: 100/167 Loss: 18.112902
2023-05-18 15:59: Train Epoch 94: 120/167 Loss: 18.931637
2023-05-18 15:59: Train Epoch 94: 140/167 Loss: 19.507277
2023-05-18 15:59: Train Epoch 94: 160/167 Loss: 18.543148
2023-05-18 15:59: **********Train Epoch 94: averaged Loss: 18.291346, tf_ratio: 1.000000
2023-05-18 15:59: **********Val Epoch 94: average Loss: 18.828168
2023-05-18 15:59: Train Epoch 95: 0/167 Loss: 18.046394
2023-05-18 15:59: Train Epoch 95: 20/167 Loss: 18.789192
2023-05-18 15:59: Train Epoch 95: 40/167 Loss: 18.162855
2023-05-18 15:59: Train Epoch 95: 60/167 Loss: 19.626808
2023-05-18 15:59: Train Epoch 95: 80/167 Loss: 18.061922
2023-05-18 15:59: Train Epoch 95: 100/167 Loss: 18.550154
2023-05-18 15:59: Train Epoch 95: 120/167 Loss: 18.564573
2023-05-18 15:59: Train Epoch 95: 140/167 Loss: 18.511793
2023-05-18 15:59: Train Epoch 95: 160/167 Loss: 17.955462
2023-05-18 15:59: **********Train Epoch 95: averaged Loss: 18.182715, tf_ratio: 1.000000
2023-05-18 15:59: **********Val Epoch 95: average Loss: 18.620151
2023-05-18 15:59: Train Epoch 96: 0/167 Loss: 17.076252
2023-05-18 15:59: Train Epoch 96: 20/167 Loss: 17.323902
2023-05-18 15:59: Train Epoch 96: 40/167 Loss: 18.490168
2023-05-18 15:59: Train Epoch 96: 60/167 Loss: 18.810602
2023-05-18 15:59: Train Epoch 96: 80/167 Loss: 19.116928
2023-05-18 15:59: Train Epoch 96: 100/167 Loss: 20.081129
2023-05-18 15:59: Train Epoch 96: 120/167 Loss: 18.034012
2023-05-18 15:59: Train Epoch 96: 140/167 Loss: 18.133514
2023-05-18 15:59: Train Epoch 96: 160/167 Loss: 18.144979
2023-05-18 15:59: **********Train Epoch 96: averaged Loss: 18.237212, tf_ratio: 1.000000
2023-05-18 15:59: **********Val Epoch 96: average Loss: 18.406628
2023-05-18 15:59: ******Current best model saved:model_para/PEMSD8/epoch_96.pth!
2023-05-18 15:59: Train Epoch 97: 0/167 Loss: 18.500793
2023-05-18 15:59: Train Epoch 97: 20/167 Loss: 17.740339
2023-05-18 15:59: Train Epoch 97: 40/167 Loss: 18.299841
2023-05-18 15:59: Train Epoch 97: 60/167 Loss: 18.511658
2023-05-18 16:00: Train Epoch 97: 80/167 Loss: 17.828438
2023-05-18 16:00: Train Epoch 97: 100/167 Loss: 18.549686
2023-05-18 16:00: Train Epoch 97: 120/167 Loss: 18.274284
2023-05-18 16:00: Train Epoch 97: 140/167 Loss: 17.368114
2023-05-18 16:00: Train Epoch 97: 160/167 Loss: 18.422232
2023-05-18 16:00: **********Train Epoch 97: averaged Loss: 18.198061, tf_ratio: 1.000000
2023-05-18 16:00: **********Val Epoch 97: average Loss: 18.337054
2023-05-18 16:00: ******Current best model saved:model_para/PEMSD8/epoch_97.pth!
2023-05-18 16:00: Train Epoch 98: 0/167 Loss: 17.830845
2023-05-18 16:00: Train Epoch 98: 20/167 Loss: 18.532202
2023-05-18 16:00: Train Epoch 98: 40/167 Loss: 17.386547
2023-05-18 16:00: Train Epoch 98: 60/167 Loss: 17.217920
2023-05-18 16:00: Train Epoch 98: 80/167 Loss: 18.068964
2023-05-18 16:00: Train Epoch 98: 100/167 Loss: 19.461811
2023-05-18 16:00: Train Epoch 98: 120/167 Loss: 17.588232
2023-05-18 16:00: Train Epoch 98: 140/167 Loss: 17.854658
2023-05-18 16:00: Train Epoch 98: 160/167 Loss: 17.632507
2023-05-18 16:00: **********Train Epoch 98: averaged Loss: 18.223792, tf_ratio: 1.000000
2023-05-18 16:00: **********Val Epoch 98: average Loss: 18.579985
2023-05-18 16:00: Train Epoch 99: 0/167 Loss: 18.041183
2023-05-18 16:00: Train Epoch 99: 20/167 Loss: 17.295866
2023-05-18 16:00: Train Epoch 99: 40/167 Loss: 17.838572
2023-05-18 16:00: Train Epoch 99: 60/167 Loss: 18.573833
2023-05-18 16:00: Train Epoch 99: 80/167 Loss: 17.240549
2023-05-18 16:00: Train Epoch 99: 100/167 Loss: 18.090818
2023-05-18 16:00: Train Epoch 99: 120/167 Loss: 17.881250
2023-05-18 16:00: Train Epoch 99: 140/167 Loss: 18.535534
2023-05-18 16:00: Train Epoch 99: 160/167 Loss: 17.089657
2023-05-18 16:00: **********Train Epoch 99: averaged Loss: 18.129840, tf_ratio: 1.000000
2023-05-18 16:00: **********Val Epoch 99: average Loss: 18.522051
2023-05-18 16:00: Train Epoch 100: 0/167 Loss: 18.706179
2023-05-18 16:00: Train Epoch 100: 20/167 Loss: 19.216278
2023-05-18 16:00: Train Epoch 100: 40/167 Loss: 19.091179
2023-05-18 16:00: Train Epoch 100: 60/167 Loss: 18.794161
2023-05-18 16:00: Train Epoch 100: 80/167 Loss: 18.751921
2023-05-18 16:01: Train Epoch 100: 100/167 Loss: 18.565145
2023-05-18 16:01: Train Epoch 100: 120/167 Loss: 18.158058
2023-05-18 16:01: Train Epoch 100: 140/167 Loss: 17.590250
2023-05-18 16:01: Train Epoch 100: 160/167 Loss: 17.639742
2023-05-18 16:01: **********Train Epoch 100: averaged Loss: 18.292196, tf_ratio: 1.000000
2023-05-18 16:01: **********Val Epoch 100: average Loss: 18.328209
2023-05-18 16:01: ******Current best model saved:model_para/PEMSD8/epoch_100.pth!
2023-05-18 16:01: Train Epoch 101: 0/167 Loss: 17.206947
2023-05-18 16:01: Train Epoch 101: 20/167 Loss: 17.779051
2023-05-18 16:01: Train Epoch 101: 40/167 Loss: 17.978918
2023-05-18 16:01: Train Epoch 101: 60/167 Loss: 17.007507
2023-05-18 16:01: Train Epoch 101: 80/167 Loss: 18.021471
2023-05-18 16:01: Train Epoch 101: 100/167 Loss: 17.837351
2023-05-18 16:01: Train Epoch 101: 120/167 Loss: 17.804548
2023-05-18 16:01: Train Epoch 101: 140/167 Loss: 17.392653
2023-05-18 16:01: Train Epoch 101: 160/167 Loss: 17.750607
2023-05-18 16:01: **********Train Epoch 101: averaged Loss: 17.930226, tf_ratio: 1.000000
2023-05-18 16:01: **********Val Epoch 101: average Loss: 18.334628
2023-05-18 16:01: Train Epoch 102: 0/167 Loss: 18.012199
2023-05-18 16:01: Train Epoch 102: 20/167 Loss: 18.631073
2023-05-18 16:01: Train Epoch 102: 40/167 Loss: 18.128912
2023-05-18 16:01: Train Epoch 102: 60/167 Loss: 18.525242
2023-05-18 16:01: Train Epoch 102: 80/167 Loss: 17.989904
2023-05-18 16:01: Train Epoch 102: 100/167 Loss: 19.742786
2023-05-18 16:01: Train Epoch 102: 120/167 Loss: 17.900326
2023-05-18 16:01: Train Epoch 102: 140/167 Loss: 17.511957
2023-05-18 16:01: Train Epoch 102: 160/167 Loss: 17.011673
2023-05-18 16:01: **********Train Epoch 102: averaged Loss: 17.953555, tf_ratio: 1.000000
2023-05-18 16:01: **********Val Epoch 102: average Loss: 18.265501
2023-05-18 16:01: ******Current best model saved:model_para/PEMSD8/epoch_102.pth!
2023-05-18 16:01: Train Epoch 103: 0/167 Loss: 17.480392
2023-05-18 16:01: Train Epoch 103: 20/167 Loss: 18.352383
2023-05-18 16:01: Train Epoch 103: 40/167 Loss: 17.721952
2023-05-18 16:01: Train Epoch 103: 60/167 Loss: 18.614401
2023-05-18 16:01: Train Epoch 103: 80/167 Loss: 17.740112
2023-05-18 16:01: Train Epoch 103: 100/167 Loss: 18.662590
2023-05-18 16:02: Train Epoch 103: 120/167 Loss: 17.162935
2023-05-18 16:02: Train Epoch 103: 140/167 Loss: 18.079464
2023-05-18 16:02: Train Epoch 103: 160/167 Loss: 18.053732
2023-05-18 16:02: **********Train Epoch 103: averaged Loss: 17.909629, tf_ratio: 1.000000
2023-05-18 16:02: **********Val Epoch 103: average Loss: 18.248169
2023-05-18 16:02: ******Current best model saved:model_para/PEMSD8/epoch_103.pth!
2023-05-18 16:02: Train Epoch 104: 0/167 Loss: 17.748634
2023-05-18 16:02: Train Epoch 104: 20/167 Loss: 19.261776
2023-05-18 16:02: Train Epoch 104: 40/167 Loss: 17.742056
2023-05-18 16:02: Train Epoch 104: 60/167 Loss: 17.790068
2023-05-18 16:02: Train Epoch 104: 80/167 Loss: 19.157297
2023-05-18 16:02: Train Epoch 104: 100/167 Loss: 18.264820
2023-05-18 16:02: Train Epoch 104: 120/167 Loss: 17.865450
2023-05-18 16:02: Train Epoch 104: 140/167 Loss: 19.047337
2023-05-18 16:02: Train Epoch 104: 160/167 Loss: 16.913298
2023-05-18 16:02: **********Train Epoch 104: averaged Loss: 17.946311, tf_ratio: 1.000000
2023-05-18 16:02: **********Val Epoch 104: average Loss: 18.270702
2023-05-18 16:02: Train Epoch 105: 0/167 Loss: 19.124189
2023-05-18 16:02: Train Epoch 105: 20/167 Loss: 18.064232
2023-05-18 16:02: Train Epoch 105: 40/167 Loss: 17.456762
2023-05-18 16:02: Train Epoch 105: 60/167 Loss: 18.410927
2023-05-18 16:02: Train Epoch 105: 80/167 Loss: 18.088118
2023-05-18 16:02: Train Epoch 105: 100/167 Loss: 18.780687
2023-05-18 16:02: Train Epoch 105: 120/167 Loss: 18.703743
2023-05-18 16:02: Train Epoch 105: 140/167 Loss: 18.488237
2023-05-18 16:02: Train Epoch 105: 160/167 Loss: 17.418098
2023-05-18 16:02: **********Train Epoch 105: averaged Loss: 17.903237, tf_ratio: 1.000000
2023-05-18 16:02: **********Val Epoch 105: average Loss: 18.361211
2023-05-18 16:02: Train Epoch 106: 0/167 Loss: 18.418066
2023-05-18 16:02: Train Epoch 106: 20/167 Loss: 18.115496
2023-05-18 16:02: Train Epoch 106: 40/167 Loss: 16.220509
2023-05-18 16:02: Train Epoch 106: 60/167 Loss: 18.956696
2023-05-18 16:02: Train Epoch 106: 80/167 Loss: 17.105171
2023-05-18 16:02: Train Epoch 106: 100/167 Loss: 18.237215
2023-05-18 16:02: Train Epoch 106: 120/167 Loss: 18.321199
2023-05-18 16:02: Train Epoch 106: 140/167 Loss: 18.795607
2023-05-18 16:03: Train Epoch 106: 160/167 Loss: 17.479624
2023-05-18 16:03: **********Train Epoch 106: averaged Loss: 17.952082, tf_ratio: 1.000000
2023-05-18 16:03: **********Val Epoch 106: average Loss: 18.290309
2023-05-18 16:03: Train Epoch 107: 0/167 Loss: 18.038504
2023-05-18 16:03: Train Epoch 107: 20/167 Loss: 16.866199
2023-05-18 16:03: Train Epoch 107: 40/167 Loss: 18.438259
2023-05-18 16:03: Train Epoch 107: 60/167 Loss: 16.894678
2023-05-18 16:03: Train Epoch 107: 80/167 Loss: 18.536312
2023-05-18 16:03: Train Epoch 107: 100/167 Loss: 17.553627
2023-05-18 16:03: Train Epoch 107: 120/167 Loss: 17.099092
2023-05-18 16:03: Train Epoch 107: 140/167 Loss: 18.909353
2023-05-18 16:03: Train Epoch 107: 160/167 Loss: 18.007689
2023-05-18 16:03: **********Train Epoch 107: averaged Loss: 17.929260, tf_ratio: 1.000000
2023-05-18 16:03: **********Val Epoch 107: average Loss: 18.318325
2023-05-18 16:03: Train Epoch 108: 0/167 Loss: 18.237930
2023-05-18 16:03: Train Epoch 108: 20/167 Loss: 17.131420
2023-05-18 16:03: Train Epoch 108: 40/167 Loss: 18.609818
2023-05-18 16:03: Train Epoch 108: 60/167 Loss: 18.333546
2023-05-18 16:03: Train Epoch 108: 80/167 Loss: 18.240664
2023-05-18 16:03: Train Epoch 108: 100/167 Loss: 18.167238
2023-05-18 16:03: Train Epoch 108: 120/167 Loss: 17.518515
2023-05-18 16:03: Train Epoch 108: 140/167 Loss: 17.353411
2023-05-18 16:03: Train Epoch 108: 160/167 Loss: 18.393173
2023-05-18 16:03: **********Train Epoch 108: averaged Loss: 17.921899, tf_ratio: 1.000000
2023-05-18 16:03: **********Val Epoch 108: average Loss: 18.253726
2023-05-18 16:03: Train Epoch 109: 0/167 Loss: 16.947287
2023-05-18 16:03: Train Epoch 109: 20/167 Loss: 18.228727
2023-05-18 16:03: Train Epoch 109: 40/167 Loss: 17.581083
2023-05-18 16:03: Train Epoch 109: 60/167 Loss: 16.697811
2023-05-18 16:03: Train Epoch 109: 80/167 Loss: 17.079798
2023-05-18 16:03: Train Epoch 109: 100/167 Loss: 17.618641
2023-05-18 16:03: Train Epoch 109: 120/167 Loss: 17.171406
2023-05-18 16:03: Train Epoch 109: 140/167 Loss: 17.932514
2023-05-18 16:03: Train Epoch 109: 160/167 Loss: 17.216143
2023-05-18 16:03: **********Train Epoch 109: averaged Loss: 17.898413, tf_ratio: 1.000000
2023-05-18 16:04: **********Val Epoch 109: average Loss: 18.222406
2023-05-18 16:04: ******Current best model saved:model_para/PEMSD8/epoch_109.pth!
2023-05-18 16:04: Train Epoch 110: 0/167 Loss: 17.133249
2023-05-18 16:04: Train Epoch 110: 20/167 Loss: 18.468035
2023-05-18 16:04: Train Epoch 110: 40/167 Loss: 18.257498
2023-05-18 16:04: Train Epoch 110: 60/167 Loss: 18.620539
2023-05-18 16:04: Train Epoch 110: 80/167 Loss: 18.792181
2023-05-18 16:04: Train Epoch 110: 100/167 Loss: 17.351658
2023-05-18 16:04: Train Epoch 110: 120/167 Loss: 17.294470
2023-05-18 16:04: Train Epoch 110: 140/167 Loss: 17.449314
2023-05-18 16:04: Train Epoch 110: 160/167 Loss: 17.836555
2023-05-18 16:04: **********Train Epoch 110: averaged Loss: 17.915720, tf_ratio: 1.000000
2023-05-18 16:04: **********Val Epoch 110: average Loss: 18.957569
2023-05-18 16:04: Train Epoch 111: 0/167 Loss: 18.078867
2023-05-18 16:04: Train Epoch 111: 20/167 Loss: 18.723505
2023-05-18 16:04: Train Epoch 111: 40/167 Loss: 16.816694
2023-05-18 16:04: Train Epoch 111: 60/167 Loss: 18.623842
2023-05-18 16:04: Train Epoch 111: 80/167 Loss: 17.808599
2023-05-18 16:04: Train Epoch 111: 100/167 Loss: 17.525587
2023-05-18 16:04: Train Epoch 111: 120/167 Loss: 17.257868
2023-05-18 16:04: Train Epoch 111: 140/167 Loss: 18.773392
2023-05-18 16:04: Train Epoch 111: 160/167 Loss: 17.864897
2023-05-18 16:04: **********Train Epoch 111: averaged Loss: 17.910665, tf_ratio: 1.000000
2023-05-18 16:04: **********Val Epoch 111: average Loss: 18.560445
2023-05-18 16:04: Train Epoch 112: 0/167 Loss: 18.415245
2023-05-18 16:04: Train Epoch 112: 20/167 Loss: 19.071352
2023-05-18 16:04: Train Epoch 112: 40/167 Loss: 19.148634
2023-05-18 16:04: Train Epoch 112: 60/167 Loss: 18.282166
2023-05-18 16:04: Train Epoch 112: 80/167 Loss: 19.247078
2023-05-18 16:04: Train Epoch 112: 100/167 Loss: 17.513321
2023-05-18 16:04: Train Epoch 112: 120/167 Loss: 17.452990
2023-05-18 16:04: Train Epoch 112: 140/167 Loss: 17.797354
2023-05-18 16:04: Train Epoch 112: 160/167 Loss: 17.016302
2023-05-18 16:04: **********Train Epoch 112: averaged Loss: 17.920501, tf_ratio: 1.000000
2023-05-18 16:04: **********Val Epoch 112: average Loss: 18.323883
2023-05-18 16:04: Train Epoch 113: 0/167 Loss: 16.708748
2023-05-18 16:05: Train Epoch 113: 20/167 Loss: 17.666702
2023-05-18 16:05: Train Epoch 113: 40/167 Loss: 15.984545
2023-05-18 16:05: Train Epoch 113: 60/167 Loss: 17.467226
2023-05-18 16:05: Train Epoch 113: 80/167 Loss: 17.383890
2023-05-18 16:05: Train Epoch 113: 100/167 Loss: 18.312883
2023-05-18 16:05: Train Epoch 113: 120/167 Loss: 16.649719
2023-05-18 16:05: Train Epoch 113: 140/167 Loss: 17.870087
2023-05-18 16:05: Train Epoch 113: 160/167 Loss: 16.821638
2023-05-18 16:05: **********Train Epoch 113: averaged Loss: 17.925498, tf_ratio: 1.000000
2023-05-18 16:05: **********Val Epoch 113: average Loss: 18.188923
2023-05-18 16:05: ******Current best model saved:model_para/PEMSD8/epoch_113.pth!
2023-05-18 16:05: Train Epoch 114: 0/167 Loss: 18.082365
2023-05-18 16:05: Train Epoch 114: 20/167 Loss: 17.107288
2023-05-18 16:05: Train Epoch 114: 40/167 Loss: 16.900595
2023-05-18 16:05: Train Epoch 114: 60/167 Loss: 17.987209
2023-05-18 16:05: Train Epoch 114: 80/167 Loss: 18.012796
2023-05-18 16:05: Train Epoch 114: 100/167 Loss: 17.342354
2023-05-18 16:05: Train Epoch 114: 120/167 Loss: 17.203756
2023-05-18 16:05: Train Epoch 114: 140/167 Loss: 17.605038
2023-05-18 16:05: Train Epoch 114: 160/167 Loss: 17.839951
2023-05-18 16:05: **********Train Epoch 114: averaged Loss: 17.935357, tf_ratio: 1.000000
2023-05-18 16:05: **********Val Epoch 114: average Loss: 18.227899
2023-05-18 16:05: Train Epoch 115: 0/167 Loss: 18.340097
2023-05-18 16:05: Train Epoch 115: 20/167 Loss: 17.077398
2023-05-18 16:05: Train Epoch 115: 40/167 Loss: 18.338459
2023-05-18 16:05: Train Epoch 115: 60/167 Loss: 17.945889
2023-05-18 16:05: Train Epoch 115: 80/167 Loss: 16.967987
2023-05-18 16:05: Train Epoch 115: 100/167 Loss: 17.579145
2023-05-18 16:05: Train Epoch 115: 120/167 Loss: 17.448914
2023-05-18 16:05: Train Epoch 115: 140/167 Loss: 18.418406
2023-05-18 16:05: Train Epoch 115: 160/167 Loss: 18.246876
2023-05-18 16:05: **********Train Epoch 115: averaged Loss: 17.847817, tf_ratio: 1.000000
2023-05-18 16:05: **********Val Epoch 115: average Loss: 18.169115
2023-05-18 16:05: ******Current best model saved:model_para/PEMSD8/epoch_115.pth!
2023-05-18 16:05: Train Epoch 116: 0/167 Loss: 17.351818
2023-05-18 16:05: Train Epoch 116: 20/167 Loss: 17.723320
2023-05-18 16:06: Train Epoch 116: 40/167 Loss: 19.135643
2023-05-18 16:06: Train Epoch 116: 60/167 Loss: 17.965481
2023-05-18 16:06: Train Epoch 116: 80/167 Loss: 19.390654
2023-05-18 16:06: Train Epoch 116: 100/167 Loss: 17.668444
2023-05-18 16:06: Train Epoch 116: 120/167 Loss: 17.676992
2023-05-18 16:06: Train Epoch 116: 140/167 Loss: 17.459629
2023-05-18 16:06: Train Epoch 116: 160/167 Loss: 17.840075
2023-05-18 16:06: **********Train Epoch 116: averaged Loss: 17.895876, tf_ratio: 1.000000
2023-05-18 16:06: **********Val Epoch 116: average Loss: 18.421291
2023-05-18 16:06: Train Epoch 117: 0/167 Loss: 18.227236
2023-05-18 16:06: Train Epoch 117: 20/167 Loss: 17.535028
2023-05-18 16:06: Train Epoch 117: 40/167 Loss: 17.114199
2023-05-18 16:06: Train Epoch 117: 60/167 Loss: 18.160372
2023-05-18 16:06: Train Epoch 117: 80/167 Loss: 18.875036
2023-05-18 16:06: Train Epoch 117: 100/167 Loss: 18.066595
2023-05-18 16:06: Train Epoch 117: 120/167 Loss: 17.869617
2023-05-18 16:06: Train Epoch 117: 140/167 Loss: 18.560917
2023-05-18 16:06: Train Epoch 117: 160/167 Loss: 17.456297
2023-05-18 16:06: **********Train Epoch 117: averaged Loss: 17.861436, tf_ratio: 1.000000
2023-05-18 16:06: **********Val Epoch 117: average Loss: 18.248008
2023-05-18 16:06: Train Epoch 118: 0/167 Loss: 19.272209
2023-05-18 16:06: Train Epoch 118: 20/167 Loss: 17.996153
2023-05-18 16:06: Train Epoch 118: 40/167 Loss: 18.504992
2023-05-18 16:06: Train Epoch 118: 60/167 Loss: 16.641973
2023-05-18 16:06: Train Epoch 118: 80/167 Loss: 18.010820
2023-05-18 16:06: Train Epoch 118: 100/167 Loss: 16.955837
2023-05-18 16:06: Train Epoch 118: 120/167 Loss: 19.208916
2023-05-18 16:06: Train Epoch 118: 140/167 Loss: 18.900721
2023-05-18 16:06: Train Epoch 118: 160/167 Loss: 17.412022
2023-05-18 16:06: **********Train Epoch 118: averaged Loss: 17.878697, tf_ratio: 1.000000
2023-05-18 16:06: **********Val Epoch 118: average Loss: 18.188609
2023-05-18 16:06: Train Epoch 119: 0/167 Loss: 17.527504
2023-05-18 16:06: Train Epoch 119: 20/167 Loss: 18.055435
2023-05-18 16:06: Train Epoch 119: 40/167 Loss: 16.583889
2023-05-18 16:07: Train Epoch 119: 60/167 Loss: 17.237719
2023-05-18 16:07: Train Epoch 119: 80/167 Loss: 17.282248
2023-05-18 16:07: Train Epoch 119: 100/167 Loss: 17.385920
2023-05-18 16:07: Train Epoch 119: 120/167 Loss: 17.407438
2023-05-18 16:07: Train Epoch 119: 140/167 Loss: 17.402567
2023-05-18 16:07: Train Epoch 119: 160/167 Loss: 18.276430
2023-05-18 16:07: **********Train Epoch 119: averaged Loss: 17.859380, tf_ratio: 1.000000
2023-05-18 16:07: **********Val Epoch 119: average Loss: 18.166373
2023-05-18 16:07: ******Current best model saved:model_para/PEMSD8/epoch_119.pth!
2023-05-18 16:07: Train Epoch 120: 0/167 Loss: 18.593126
2023-05-18 16:07: Train Epoch 120: 20/167 Loss: 17.066656
2023-05-18 16:07: Train Epoch 120: 40/167 Loss: 17.490208
2023-05-18 16:07: Train Epoch 120: 60/167 Loss: 17.563381
2023-05-18 16:07: Train Epoch 120: 80/167 Loss: 18.078112
2023-05-18 16:07: Train Epoch 120: 100/167 Loss: 19.025002
2023-05-18 16:07: Train Epoch 120: 120/167 Loss: 17.484571
2023-05-18 16:07: Train Epoch 120: 140/167 Loss: 16.094604
2023-05-18 16:07: Train Epoch 120: 160/167 Loss: 18.520786
2023-05-18 16:07: **********Train Epoch 120: averaged Loss: 17.868387, tf_ratio: 1.000000
2023-05-18 16:07: **********Val Epoch 120: average Loss: 18.133278
2023-05-18 16:07: ******Current best model saved:model_para/PEMSD8/epoch_120.pth!
2023-05-18 16:07: Train Epoch 121: 0/167 Loss: 17.904573
2023-05-18 16:07: Train Epoch 121: 20/167 Loss: 19.174896
2023-05-18 16:07: Train Epoch 121: 40/167 Loss: 17.437328
2023-05-18 16:07: Train Epoch 121: 60/167 Loss: 16.343676
2023-05-18 16:07: Train Epoch 121: 80/167 Loss: 17.942785
2023-05-18 16:07: Train Epoch 121: 100/167 Loss: 19.195566
2023-05-18 16:07: Train Epoch 121: 120/167 Loss: 17.951254
2023-05-18 16:07: Train Epoch 121: 140/167 Loss: 17.090431
2023-05-18 16:07: Train Epoch 121: 160/167 Loss: 18.359028
2023-05-18 16:07: **********Train Epoch 121: averaged Loss: 17.868214, tf_ratio: 1.000000
2023-05-18 16:07: **********Val Epoch 121: average Loss: 18.173744
2023-05-18 16:07: Train Epoch 122: 0/167 Loss: 16.276930
2023-05-18 16:07: Train Epoch 122: 20/167 Loss: 16.562351
2023-05-18 16:07: Train Epoch 122: 40/167 Loss: 18.543077
2023-05-18 16:07: Train Epoch 122: 60/167 Loss: 17.026726
2023-05-18 16:07: Train Epoch 122: 80/167 Loss: 18.020798
2023-05-18 16:08: Train Epoch 122: 100/167 Loss: 17.279726
2023-05-18 16:08: Train Epoch 122: 120/167 Loss: 16.892164
2023-05-18 16:08: Train Epoch 122: 140/167 Loss: 17.598791
2023-05-18 16:08: Train Epoch 122: 160/167 Loss: 17.917423
2023-05-18 16:08: **********Train Epoch 122: averaged Loss: 17.885174, tf_ratio: 1.000000
2023-05-18 16:08: **********Val Epoch 122: average Loss: 18.278866
2023-05-18 16:08: Train Epoch 123: 0/167 Loss: 18.388689
2023-05-18 16:08: Train Epoch 123: 20/167 Loss: 18.454336
2023-05-18 16:08: Train Epoch 123: 40/167 Loss: 17.255354
2023-05-18 16:08: Train Epoch 123: 60/167 Loss: 17.333269
2023-05-18 16:08: Train Epoch 123: 80/167 Loss: 18.486361
2023-05-18 16:08: Train Epoch 123: 100/167 Loss: 18.511703
2023-05-18 16:08: Train Epoch 123: 120/167 Loss: 18.456726
2023-05-18 16:08: Train Epoch 123: 140/167 Loss: 16.786848
2023-05-18 16:08: Train Epoch 123: 160/167 Loss: 18.137911
2023-05-18 16:08: **********Train Epoch 123: averaged Loss: 17.817798, tf_ratio: 1.000000
2023-05-18 16:08: **********Val Epoch 123: average Loss: 18.127977
2023-05-18 16:08: ******Current best model saved:model_para/PEMSD8/epoch_123.pth!
2023-05-18 16:08: Train Epoch 124: 0/167 Loss: 17.875048
2023-05-18 16:08: Train Epoch 124: 20/167 Loss: 16.959679
2023-05-18 16:08: Train Epoch 124: 40/167 Loss: 16.694853
2023-05-18 16:08: Train Epoch 124: 60/167 Loss: 18.183243
2023-05-18 16:08: Train Epoch 124: 80/167 Loss: 18.028692
2023-05-18 16:08: Train Epoch 124: 100/167 Loss: 17.881771
2023-05-18 16:08: Train Epoch 124: 120/167 Loss: 18.801594
2023-05-18 16:08: Train Epoch 124: 140/167 Loss: 16.800882
2023-05-18 16:08: Train Epoch 124: 160/167 Loss: 16.644485
2023-05-18 16:08: **********Train Epoch 124: averaged Loss: 17.865705, tf_ratio: 1.000000
2023-05-18 16:08: **********Val Epoch 124: average Loss: 18.157263
2023-05-18 16:08: Train Epoch 125: 0/167 Loss: 19.145525
2023-05-18 16:08: Train Epoch 125: 20/167 Loss: 18.013487
2023-05-18 16:08: Train Epoch 125: 40/167 Loss: 17.009310
2023-05-18 16:08: Train Epoch 125: 60/167 Loss: 17.271603
2023-05-18 16:08: Train Epoch 125: 80/167 Loss: 17.131735
2023-05-18 16:08: Train Epoch 125: 100/167 Loss: 18.015160
2023-05-18 16:08: Train Epoch 125: 120/167 Loss: 17.060040
2023-05-18 16:09: Train Epoch 125: 140/167 Loss: 16.940586
2023-05-18 16:09: Train Epoch 125: 160/167 Loss: 17.221846
2023-05-18 16:09: **********Train Epoch 125: averaged Loss: 17.803715, tf_ratio: 1.000000
2023-05-18 16:09: **********Val Epoch 125: average Loss: 18.350886
2023-05-18 16:09: Train Epoch 126: 0/167 Loss: 17.045067
2023-05-18 16:09: Train Epoch 126: 20/167 Loss: 16.644552
2023-05-18 16:09: Train Epoch 126: 40/167 Loss: 17.273565
2023-05-18 16:09: Train Epoch 126: 60/167 Loss: 17.095024
2023-05-18 16:09: Train Epoch 126: 80/167 Loss: 17.446920
2023-05-18 16:09: Train Epoch 126: 100/167 Loss: 17.572655
2023-05-18 16:09: Train Epoch 126: 120/167 Loss: 17.266905
2023-05-18 16:09: Train Epoch 126: 140/167 Loss: 18.120804
2023-05-18 16:09: Train Epoch 126: 160/167 Loss: 19.307676
2023-05-18 16:09: **********Train Epoch 126: averaged Loss: 17.815609, tf_ratio: 1.000000
2023-05-18 16:09: **********Val Epoch 126: average Loss: 18.302697
2023-05-18 16:09: Train Epoch 127: 0/167 Loss: 17.352528
2023-05-18 16:09: Train Epoch 127: 20/167 Loss: 17.820999
2023-05-18 16:09: Train Epoch 127: 40/167 Loss: 16.997894
2023-05-18 16:09: Train Epoch 127: 60/167 Loss: 17.991817
2023-05-18 16:09: Train Epoch 127: 80/167 Loss: 17.462290
2023-05-18 16:09: Train Epoch 127: 100/167 Loss: 17.495510
2023-05-18 16:09: Train Epoch 127: 120/167 Loss: 18.272581
2023-05-18 16:09: Train Epoch 127: 140/167 Loss: 17.217377
2023-05-18 16:09: Train Epoch 127: 160/167 Loss: 20.306761
2023-05-18 16:09: **********Train Epoch 127: averaged Loss: 17.848851, tf_ratio: 1.000000
2023-05-18 16:09: **********Val Epoch 127: average Loss: 18.164623
2023-05-18 16:09: Train Epoch 128: 0/167 Loss: 19.106056
2023-05-18 16:09: Train Epoch 128: 20/167 Loss: 17.084314
2023-05-18 16:09: Train Epoch 128: 40/167 Loss: 17.985481
2023-05-18 16:09: Train Epoch 128: 60/167 Loss: 17.744949
2023-05-18 16:09: Train Epoch 128: 80/167 Loss: 15.990540
2023-05-18 16:09: Train Epoch 128: 100/167 Loss: 17.927084
2023-05-18 16:09: Train Epoch 128: 120/167 Loss: 16.058554
2023-05-18 16:09: Train Epoch 128: 140/167 Loss: 19.010216
2023-05-18 16:09: Train Epoch 128: 160/167 Loss: 16.499897
2023-05-18 16:09: **********Train Epoch 128: averaged Loss: 17.849065, tf_ratio: 1.000000
2023-05-18 16:10: **********Val Epoch 128: average Loss: 18.120483
2023-05-18 16:10: ******Current best model saved:model_para/PEMSD8/epoch_128.pth!
2023-05-18 16:10: Train Epoch 129: 0/167 Loss: 17.864588
2023-05-18 16:10: Train Epoch 129: 20/167 Loss: 17.642893
2023-05-18 16:10: Train Epoch 129: 40/167 Loss: 18.700178
2023-05-18 16:10: Train Epoch 129: 60/167 Loss: 18.266867
2023-05-18 16:10: Train Epoch 129: 80/167 Loss: 16.233614
2023-05-18 16:10: Train Epoch 129: 100/167 Loss: 17.583946
2023-05-18 16:10: Train Epoch 129: 120/167 Loss: 16.834167
2023-05-18 16:10: Train Epoch 129: 140/167 Loss: 17.076813
2023-05-18 16:10: Train Epoch 129: 160/167 Loss: 17.539730
2023-05-18 16:10: **********Train Epoch 129: averaged Loss: 17.822431, tf_ratio: 1.000000
2023-05-18 16:10: **********Val Epoch 129: average Loss: 18.315769
2023-05-18 16:10: Train Epoch 130: 0/167 Loss: 17.524372
2023-05-18 16:10: Train Epoch 130: 20/167 Loss: 17.471439
2023-05-18 16:10: Train Epoch 130: 40/167 Loss: 17.447762
2023-05-18 16:10: Train Epoch 130: 60/167 Loss: 18.698765
2023-05-18 16:10: Train Epoch 130: 80/167 Loss: 17.117094
2023-05-18 16:10: Train Epoch 130: 100/167 Loss: 17.411968
2023-05-18 16:10: Train Epoch 130: 120/167 Loss: 17.999588
2023-05-18 16:10: Train Epoch 130: 140/167 Loss: 17.336678
2023-05-18 16:10: Train Epoch 130: 160/167 Loss: 19.567631
2023-05-18 16:10: **********Train Epoch 130: averaged Loss: 17.860144, tf_ratio: 1.000000
2023-05-18 16:10: **********Val Epoch 130: average Loss: 18.063941
2023-05-18 16:10: ******Current best model saved:model_para/PEMSD8/epoch_130.pth!
2023-05-18 16:10: Train Epoch 131: 0/167 Loss: 16.870457
2023-05-18 16:10: Train Epoch 131: 20/167 Loss: 16.811325
2023-05-18 16:10: Train Epoch 131: 40/167 Loss: 18.384802
2023-05-18 16:10: Train Epoch 131: 60/167 Loss: 17.670214
2023-05-18 16:10: Train Epoch 131: 80/167 Loss: 18.740335
2023-05-18 16:10: Train Epoch 131: 100/167 Loss: 18.383390
2023-05-18 16:10: Train Epoch 131: 120/167 Loss: 16.715994
2023-05-18 16:10: Train Epoch 131: 140/167 Loss: 18.118719
2023-05-18 16:10: Train Epoch 131: 160/167 Loss: 17.349150
2023-05-18 16:10: **********Train Epoch 131: averaged Loss: 17.849169, tf_ratio: 1.000000
2023-05-18 16:10: **********Val Epoch 131: average Loss: 18.266981
2023-05-18 16:10: Train Epoch 132: 0/167 Loss: 17.051624
2023-05-18 16:10: Train Epoch 132: 20/167 Loss: 18.889488
2023-05-18 16:11: Train Epoch 132: 40/167 Loss: 16.328108
2023-05-18 16:11: Train Epoch 132: 60/167 Loss: 16.345638
2023-05-18 16:11: Train Epoch 132: 80/167 Loss: 16.859495
2023-05-18 16:11: Train Epoch 132: 100/167 Loss: 17.740913
2023-05-18 16:11: Train Epoch 132: 120/167 Loss: 16.183805
2023-05-18 16:11: Train Epoch 132: 140/167 Loss: 17.324278
2023-05-18 16:11: Train Epoch 132: 160/167 Loss: 17.292755
2023-05-18 16:11: **********Train Epoch 132: averaged Loss: 17.839188, tf_ratio: 1.000000
2023-05-18 16:11: **********Val Epoch 132: average Loss: 18.136406
2023-05-18 16:11: Train Epoch 133: 0/167 Loss: 17.326756
2023-05-18 16:11: Train Epoch 133: 20/167 Loss: 18.526917
2023-05-18 16:11: Train Epoch 133: 40/167 Loss: 17.385979
2023-05-18 16:11: Train Epoch 133: 60/167 Loss: 18.373617
2023-05-18 16:11: Train Epoch 133: 80/167 Loss: 17.822952
2023-05-18 16:11: Train Epoch 133: 100/167 Loss: 17.932354
2023-05-18 16:11: Train Epoch 133: 120/167 Loss: 16.785633
2023-05-18 16:11: Train Epoch 133: 140/167 Loss: 18.431484
2023-05-18 16:11: Train Epoch 133: 160/167 Loss: 17.126913
2023-05-18 16:11: **********Train Epoch 133: averaged Loss: 17.797979, tf_ratio: 1.000000
2023-05-18 16:11: **********Val Epoch 133: average Loss: 18.144763
2023-05-18 16:11: Train Epoch 134: 0/167 Loss: 17.350876
2023-05-18 16:11: Train Epoch 134: 20/167 Loss: 16.523893
2023-05-18 16:11: Train Epoch 134: 40/167 Loss: 17.938814
2023-05-18 16:11: Train Epoch 134: 60/167 Loss: 17.307384
2023-05-18 16:11: Train Epoch 134: 80/167 Loss: 17.914400
2023-05-18 16:11: Train Epoch 134: 100/167 Loss: 17.788734
2023-05-18 16:11: Train Epoch 134: 120/167 Loss: 17.347792
2023-05-18 16:11: Train Epoch 134: 140/167 Loss: 18.379328
2023-05-18 16:11: Train Epoch 134: 160/167 Loss: 17.451561
2023-05-18 16:11: **********Train Epoch 134: averaged Loss: 17.768983, tf_ratio: 1.000000
2023-05-18 16:11: **********Val Epoch 134: average Loss: 18.195968
2023-05-18 16:11: Train Epoch 135: 0/167 Loss: 20.031126
2023-05-18 16:11: Train Epoch 135: 20/167 Loss: 17.427185
2023-05-18 16:11: Train Epoch 135: 40/167 Loss: 16.670191
2023-05-18 16:11: Train Epoch 135: 60/167 Loss: 18.229347
2023-05-18 16:11: Train Epoch 135: 80/167 Loss: 17.592062
2023-05-18 16:12: Train Epoch 135: 100/167 Loss: 19.220785
2023-05-18 16:12: Train Epoch 135: 120/167 Loss: 17.621511
2023-05-18 16:12: Train Epoch 135: 140/167 Loss: 18.184866
2023-05-18 16:12: Train Epoch 135: 160/167 Loss: 16.513472
2023-05-18 16:12: **********Train Epoch 135: averaged Loss: 17.791988, tf_ratio: 1.000000
2023-05-18 16:12: **********Val Epoch 135: average Loss: 18.127870
2023-05-18 16:12: Train Epoch 136: 0/167 Loss: 16.577522
2023-05-18 16:12: Train Epoch 136: 20/167 Loss: 18.264963
2023-05-18 16:12: Train Epoch 136: 40/167 Loss: 16.720873
2023-05-18 16:12: Train Epoch 136: 60/167 Loss: 17.129274
2023-05-18 16:12: Train Epoch 136: 80/167 Loss: 17.642754
2023-05-18 16:12: Train Epoch 136: 100/167 Loss: 17.523272
2023-05-18 16:12: Train Epoch 136: 120/167 Loss: 18.515491
2023-05-18 16:12: Train Epoch 136: 140/167 Loss: 18.572151
2023-05-18 16:12: Train Epoch 136: 160/167 Loss: 16.713455
2023-05-18 16:12: **********Train Epoch 136: averaged Loss: 17.834671, tf_ratio: 1.000000
2023-05-18 16:12: **********Val Epoch 136: average Loss: 18.202659
2023-05-18 16:12: Train Epoch 137: 0/167 Loss: 17.414644
2023-05-18 16:12: Train Epoch 137: 20/167 Loss: 17.542856
2023-05-18 16:12: Train Epoch 137: 40/167 Loss: 17.298269
2023-05-18 16:12: Train Epoch 137: 60/167 Loss: 16.872431
2023-05-18 16:12: Train Epoch 137: 80/167 Loss: 19.130932
2023-05-18 16:12: Train Epoch 137: 100/167 Loss: 17.405048
2023-05-18 16:12: Train Epoch 137: 120/167 Loss: 18.205631
2023-05-18 16:12: Train Epoch 137: 140/167 Loss: 18.047884
2023-05-18 16:12: Train Epoch 137: 160/167 Loss: 18.578266
2023-05-18 16:12: **********Train Epoch 137: averaged Loss: 17.775775, tf_ratio: 1.000000
2023-05-18 16:12: **********Val Epoch 137: average Loss: 18.140014
2023-05-18 16:12: Train Epoch 138: 0/167 Loss: 18.169220
2023-05-18 16:12: Train Epoch 138: 20/167 Loss: 18.183798
2023-05-18 16:12: Train Epoch 138: 40/167 Loss: 16.362820
2023-05-18 16:12: Train Epoch 138: 60/167 Loss: 17.518988
2023-05-18 16:12: Train Epoch 138: 80/167 Loss: 17.432138
2023-05-18 16:12: Train Epoch 138: 100/167 Loss: 18.042072
2023-05-18 16:12: Train Epoch 138: 120/167 Loss: 18.299953
2023-05-18 16:13: Train Epoch 138: 140/167 Loss: 18.539448
2023-05-18 16:13: Train Epoch 138: 160/167 Loss: 17.105381
2023-05-18 16:13: **********Train Epoch 138: averaged Loss: 17.756635, tf_ratio: 1.000000
2023-05-18 16:13: **********Val Epoch 138: average Loss: 18.104546
2023-05-18 16:13: Train Epoch 139: 0/167 Loss: 18.945576
2023-05-18 16:13: Train Epoch 139: 20/167 Loss: 16.142056
2023-05-18 16:13: Train Epoch 139: 40/167 Loss: 17.224245
2023-05-18 16:13: Train Epoch 139: 60/167 Loss: 17.884567
2023-05-18 16:13: Train Epoch 139: 80/167 Loss: 17.115801
2023-05-18 16:13: Train Epoch 139: 100/167 Loss: 17.925035
2023-05-18 16:13: Train Epoch 139: 120/167 Loss: 18.462524
2023-05-18 16:13: Train Epoch 139: 140/167 Loss: 17.320316
2023-05-18 16:13: Train Epoch 139: 160/167 Loss: 17.218241
2023-05-18 16:13: **********Train Epoch 139: averaged Loss: 17.804405, tf_ratio: 1.000000
2023-05-18 16:13: **********Val Epoch 139: average Loss: 18.113794
2023-05-18 16:13: Train Epoch 140: 0/167 Loss: 17.175776
2023-05-18 16:13: Train Epoch 140: 20/167 Loss: 16.896925
2023-05-18 16:13: Train Epoch 140: 40/167 Loss: 18.218296
2023-05-18 16:13: Train Epoch 140: 60/167 Loss: 18.013224
2023-05-18 16:13: Train Epoch 140: 80/167 Loss: 18.248156
2023-05-18 16:13: Train Epoch 140: 100/167 Loss: 16.573919
2023-05-18 16:13: Train Epoch 140: 120/167 Loss: 18.248835
2023-05-18 16:13: Train Epoch 140: 140/167 Loss: 17.547056
2023-05-18 16:13: Train Epoch 140: 160/167 Loss: 16.994421
2023-05-18 16:13: **********Train Epoch 140: averaged Loss: 17.754876, tf_ratio: 1.000000
2023-05-18 16:13: **********Val Epoch 140: average Loss: 18.099130
2023-05-18 16:13: Train Epoch 141: 0/167 Loss: 17.744524
2023-05-18 16:13: Train Epoch 141: 20/167 Loss: 17.568073
2023-05-18 16:13: Train Epoch 141: 40/167 Loss: 19.213816
2023-05-18 16:13: Train Epoch 141: 60/167 Loss: 18.152193
2023-05-18 16:13: Train Epoch 141: 80/167 Loss: 17.996880
2023-05-18 16:13: Train Epoch 141: 100/167 Loss: 17.694450
2023-05-18 16:13: Train Epoch 141: 120/167 Loss: 17.431063
2023-05-18 16:13: Train Epoch 141: 140/167 Loss: 17.526808
2023-05-18 16:13: Train Epoch 141: 160/167 Loss: 17.406162
2023-05-18 16:13: **********Train Epoch 141: averaged Loss: 17.754989, tf_ratio: 1.000000
2023-05-18 16:14: **********Val Epoch 141: average Loss: 18.100357
2023-05-18 16:14: Train Epoch 142: 0/167 Loss: 17.488235
2023-05-18 16:14: Train Epoch 142: 20/167 Loss: 16.821430
2023-05-18 16:14: Train Epoch 142: 40/167 Loss: 18.023067
2023-05-18 16:14: Train Epoch 142: 60/167 Loss: 17.147493
2023-05-18 16:14: Train Epoch 142: 80/167 Loss: 17.343977
2023-05-18 16:14: Train Epoch 142: 100/167 Loss: 17.632431
2023-05-18 16:14: Train Epoch 142: 120/167 Loss: 16.878016
2023-05-18 16:14: Train Epoch 142: 140/167 Loss: 18.408869
2023-05-18 16:14: Train Epoch 142: 160/167 Loss: 18.741146
2023-05-18 16:14: **********Train Epoch 142: averaged Loss: 17.762784, tf_ratio: 1.000000
2023-05-18 16:14: **********Val Epoch 142: average Loss: 18.110589
2023-05-18 16:14: Train Epoch 143: 0/167 Loss: 17.651384
2023-05-18 16:14: Train Epoch 143: 20/167 Loss: 16.723673
2023-05-18 16:14: Train Epoch 143: 40/167 Loss: 18.211164
2023-05-18 16:14: Train Epoch 143: 60/167 Loss: 16.853294
2023-05-18 16:14: Train Epoch 143: 80/167 Loss: 17.496939
2023-05-18 16:14: Train Epoch 143: 100/167 Loss: 17.528677
2023-05-18 16:14: Train Epoch 143: 120/167 Loss: 16.796934
2023-05-18 16:14: Train Epoch 143: 140/167 Loss: 17.464319
2023-05-18 16:14: Train Epoch 143: 160/167 Loss: 16.747955
2023-05-18 16:14: **********Train Epoch 143: averaged Loss: 17.774644, tf_ratio: 1.000000
2023-05-18 16:14: **********Val Epoch 143: average Loss: 18.250768
2023-05-18 16:14: Train Epoch 144: 0/167 Loss: 17.864037
2023-05-18 16:14: Train Epoch 144: 20/167 Loss: 18.998955
2023-05-18 16:14: Train Epoch 144: 40/167 Loss: 17.642487
2023-05-18 16:14: Train Epoch 144: 60/167 Loss: 17.488451
2023-05-18 16:14: Train Epoch 144: 80/167 Loss: 17.733994
2023-05-18 16:14: Train Epoch 144: 100/167 Loss: 17.147581
2023-05-18 16:14: Train Epoch 144: 120/167 Loss: 19.117012
2023-05-18 16:14: Train Epoch 144: 140/167 Loss: 18.417387
2023-05-18 16:14: Train Epoch 144: 160/167 Loss: 18.043066
2023-05-18 16:14: **********Train Epoch 144: averaged Loss: 17.764817, tf_ratio: 1.000000
2023-05-18 16:14: **********Val Epoch 144: average Loss: 18.010168
2023-05-18 16:14: ******Current best model saved:model_para/PEMSD8/epoch_144.pth!
2023-05-18 16:14: Train Epoch 145: 0/167 Loss: 17.042648
2023-05-18 16:14: Train Epoch 145: 20/167 Loss: 16.998978
2023-05-18 16:15: Train Epoch 145: 40/167 Loss: 17.260923
2023-05-18 16:15: Train Epoch 145: 60/167 Loss: 17.113104
2023-05-18 16:15: Train Epoch 145: 80/167 Loss: 17.455431
2023-05-18 16:15: Train Epoch 145: 100/167 Loss: 17.575514
2023-05-18 16:15: Train Epoch 145: 120/167 Loss: 16.626469
2023-05-18 16:15: Train Epoch 145: 140/167 Loss: 18.064451
2023-05-18 16:15: Train Epoch 145: 160/167 Loss: 18.270014
2023-05-18 16:15: **********Train Epoch 145: averaged Loss: 17.771311, tf_ratio: 1.000000
2023-05-18 16:15: **********Val Epoch 145: average Loss: 18.133857
2023-05-18 16:15: Train Epoch 146: 0/167 Loss: 17.055511
2023-05-18 16:15: Train Epoch 146: 20/167 Loss: 18.482029
